{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":""},{"location":"#chimera","title":"chimera","text":"<p>A package to translate StagYY output to seismic velocities.</p> <p>This project is developed in collaboration with the Centre for Advanced Research Computing, University College London.</p>"},{"location":"#about","title":"About","text":"<p>This simple python package allows StagYY, StagPy, axiSEM, Perple_X talk to  each other. </p> <p>It uses StagPy to load the Pressure (P), Temperature (P),  Compositional (C) and Density fields ouptut by the geodynamic modeling code  StagYY. Then, these fields are interpolated on the finer AxiSEM grid. Then, it translates the P, T fields into thermoelastic properties for  each composition (Adiabatic K, G moduli and Density). It does so based on  Perple_X thermodynamic tables supplied for each composition (a modified version of the phempg is used to import the tab file).  Then, the thermoelastic properties are averaged via a Voigt-Reuss-Hill scheme to  create a geodynamically self-consistent seismic velocity model that can be  later fed into AxiSEM as lateral heterogeneities. </p>"},{"location":"#project-team","title":"Project Team","text":"<p>Matteo Desiderio (ucfbmde@ucl.ac.uk)</p>"},{"location":"#research-software-engineering-contact","title":"Research Software Engineering Contact","text":"<p>Centre for Advanced Research Computing, University College London (arc.collaborations@ucl.ac.uk)</p>"},{"location":"#built-with","title":"Built With","text":"<ul> <li>Framework 1</li> <li>Framework 2</li> <li>Framework 3</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":""},{"location":"#prerequisites","title":"Prerequisites","text":"<p><code>chimera</code> requires Python 3.10\u20133.12.</p>"},{"location":"#installation","title":"Installation","text":"<p>We recommend installing in a project specific virtual environment created using a environment management tool such as Conda. To install the latest development version of <code>chimera</code> using <code>pip</code> in the currently active environment run</p> <pre><code>pip install git+https://github.com/MatteoDesiderio/chimera.git\n</code></pre> <p>Alternatively create a local clone of the repository with</p> <pre><code>git clone https://github.com/MatteoDesiderio/chimera.git\n</code></pre> <p>and then install in editable mode by running</p> <pre><code>pip install -e .\n</code></pre>"},{"location":"#running-locally","title":"Running Locally","text":"<p>How to run the application on your local system.</p>"},{"location":"#running-tests","title":"Running Tests","text":"<p>Tests can be run across all compatible Python versions in isolated environments using <code>tox</code> by running</p> <pre><code>tox\n</code></pre> <p>To run tests manually in a Python environment with <code>pytest</code> installed run</p> <pre><code>pytest tests\n</code></pre> <p>again from the root of the repository.</p>"},{"location":"#building-documentation","title":"Building Documentation","text":"<p>The MkDocs HTML documentation can be built locally by running</p> <pre><code>tox -e docs\n</code></pre> <p>from the root of the repository. The built documentation will be written to <code>site</code>.</p> <p>Alternatively to build and preview the documentation locally, in a Python environment with the optional <code>docs</code> dependencies installed, run</p> <pre><code>mkdocs serve\n</code></pre>"},{"location":"#roadmap","title":"Roadmap","text":"<ul> <li> Initial Research</li> <li> Minimum viable product &lt;-- You are Here</li> <li> Alpha Release</li> <li> Feature-Complete Release</li> </ul>"},{"location":"#references","title":"References","text":"<ul> <li>Tackley, P.J. (2008) 'Modelling compressible mantle convection with large viscosity contrasts in a three-dimensional spherical shell using the yin-yang grid', Physics of the Earth and Planetary Interiors, 171(1), pp. 7\u201318. Available at: https://doi.org/10.1016/j.pepi.2008.08.005.</li> <li>Connolly, J.A.D. (2005) 'Computation of phase equilibria by linear programming: A tool for geodynamic modeling and its application to subduction zone decarbonation', Earth and Planetary Science Letters, 236(1\u20132), pp. 524\u2013541. Available at: https://doi.org/10.1016/j.epsl.2005.04.033.</li> <li>Morison, A.; Ulvrova, M.; Labrosse S. ; B4rsh; theofatou; tfrass49 (2022) 'StagPython/StagPy': Zenodo. Available at: https://doi.org/10.5281/ZENODO.6388133.</li> <li>Nissen-Meyer, T.; van Driel, M.; St\u00e4hler, S. C.; Hosseini, K.; Hempel, S.; Auer, L.; Colombi, A. and Fournier, A. (2014) 'AxiSEM: broadband 3-D seismic wavefields in axisymmetric media', Solid Earth, 5(1), pp. 425\u2013445. Available at: https://doi.org/10.5194/se-5-425-2014.</li> </ul>"},{"location":"LICENSE/","title":"License","text":""},{"location":"LICENSE/#mit-license","title":"MIT License","text":"<p>Copyright (c) 2024 Matteo Desiderio</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"api/","title":"API reference","text":"<p>chimera package.</p>"},{"location":"api/#chimera.chimera_project","title":"<code>chimera_project</code>","text":""},{"location":"api/#chimera.chimera_project.Project","title":"<code>Project</code>","text":"<p>Project class.</p> Source code in <code>src/chimera/chimera_project.py</code> <pre><code>class Project:\n    \"\"\"Project class.\"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initialize project.\n\n        Returns\n        -------\n        None.\n\n        \"\"\"\n        self.test_mode_on = False\n        self.quick_mode_on = False\n        self.custom_mesh_shape = None\n        self._GY = 3600 * 24 * 364 * 1e9  # [s]\n        self.chimera_project_path = \"\"  # path where you want to save project\n        self.bg_model = \"\"  # name of your axisem bg model\n        self.thermo_data_path = \"\"  # parent path to thermo_data files\n        self.thermo_data_names = \"\"  # their names. single str of list str\n        self.stagyy_path = \"\"  # path to your stagyy models\n        self.stagyy_model_names = []\n        self.elastic_path = \"/elastic-fields/\"\n        self.vel_model_path = \"/seism_vel-fields/\"\n        self.time_span_Gy = []  # timesteps for which you want to compute vmodel\n        self.geom = None  # geom of the geodynamic models grid (same 4 all)\n        self._regular_rect_mesh = False\n\n    @property\n    def stagyy_model_names(self):\n        return self._stagyy_model_names\n\n    @stagyy_model_names.setter\n    def stagyy_model_names(self, val):\n        self._stagyy_model_names = val\n        self.t_indices = {k: [] for k in self._stagyy_model_names}\n\n    # for a quick analysis, we don't need an AxiSEM mesh to begin with\n    @property\n    def bg_model(self):\n        return self._bg_model\n\n    @bg_model.setter\n    def bg_model(self, val):\n        if self.quick_mode_on is None:\n            self._bg_model = None\n        else:\n            self._bg_model = val\n\n    # if you are using the StagYY grid, you don't need a custom grid\n    @property\n    def custom_mesh_shape(self):\n        return self._custom_mesh_shape\n\n    @custom_mesh_shape.setter\n    def custom_mesh_shape(self, val):\n        if self.quick_mode_on:\n            self._custom_mesh_shape = None\n            msg = (\n                \"Quick mode activated, but mesh shape provided: \"\n                \"custom_mesh_shape has been set to None.\"\n            )\n            warnings.warn(msg, stacklevel=2)\n        else:\n            self._custom_mesh_shape = val\n\n    def new(self, proj_name=\"New Project\"):\n        \"\"\"\n        Create a new project.\n\n        Parameters\n        ----------\n        proj_name : TYPE, optional\n            DESCRIPTION. The default is \"New Project\".\n\n        Returns\n        -------\n        None.\n\n        \"\"\"\n        self.project_name = proj_name\n        parent = self.chimera_project_path + proj_name + \"/\"\n        os.mkdir(parent)\n        geoms = []\n        for nm in self.stagyy_model_names:\n            print(\"Loading\", nm)\n            path = parent + nm\n            os.mkdir(path)\n            for t in self.time_span_Gy:\n                if self.test_mode_on:\n                    index = 0\n                else:\n                    sdat = stagyydata.StagyyData(self.stagyy_path + nm)\n                    index = sdat.snaps.at_time(t * self._GY).isnap\n                    geom = sdat.par[\"geometry\"]\n                path_snap = (path + \"/%i\") % index\n                os.mkdir(path_snap)\n                os.mkdir(path_snap + self.elastic_path)\n                os.mkdir(path_snap + self.vel_model_path)\n                self.t_indices[nm].append(index)\n            geoms.append(geom)\n\n        if not np.all(np.r_[geoms] == geom):\n            msg = \"All models must share the same geometry parameters\"\n            raise NotImplementedError(msg)\n        self.geom = geoms[0]\n\n        with open(parent + \"project_data.pkl\", \"wb\") as outp:\n            pickle.dump(self, outp, pickle.HIGHEST_PROTOCOL)\n\n    def get_mesh_xy(self):\n        \"\"\"\n        Generate x and y.\n\n        -------\n        mesh_x : TYPE\n            DESCRIPTION.\n        mesh_y : TYPE\n            DESCRIPTION.\n\n        \"\"\"\n        if self.quick_mode_on:\n            print(\"We assume all models are defined on the same grid\")\n            nm = self.stagyy_model_names[0]\n            sdat = stagyydata.StagyyData(self.stagyy_path + nm)\n            mesh_x, mesh_y = _get_mesh_xy(sdat)\n        else:\n            path_x = self.chimera_project_path + self.bg_model + \"_x.npy\"\n            path_y = self.chimera_project_path + self.bg_model + \"_y.npy\"\n            mesh_x = np.load(path_x)\n            mesh_y = np.load(path_y)\n            if self.custom_mesh_shape is not None:\n                try:\n                    shp = self.custom_mesh_shape\n                    np.reshape(mesh_x, shp)\n                    np.reshape(mesh_y, shp)\n                    self._regular_rect_mesh = True\n                    msg = (\n                        \"Mesh reshaped into provided shape. \"\n                        \"Please, check quality of result.\"\n                    )\n                    warnings.warn(msg, stacklevel=2)\n                except ValueError:\n                    self._regular_rect_mesh = False\n                    self.custom_mesh_shape = None\n                    msg = (\n                        \"cannot reshape mesh into provided shape.\"\n                        \"Continuing assuming non-rectangular, \"\n                        \"axisem-like mesh: custom_mesh_shape set to None.\"\n                    )\n                    warnings.warn(msg, stacklevel=2)\n\n        return mesh_x, mesh_y\n\n    @staticmethod\n    def load_vel_models_by_year(proj):\n        name_year_map = proj.t_indices\n        project_path = (\n            proj.chimera_project_path\n            + proj.project_name\n            + \"/{}/{}\"\n            + proj.vel_model_path\n        )\n        velocity_models_dict = {}\n        for vel_model_name in name_year_map:\n            t_indices = name_year_map[vel_model_name]\n            models_list = []\n            for t_index in t_indices:\n                model_path = project_path.format(vel_model_name, t_index)\n                vmod = VelocityModel.load(model_path)\n                models_list.append(vmod)\n            velocity_models_dict[vel_model_name] = models_list\n        return (proj, velocity_models_dict)\n\n    @staticmethod\n    def compute_profiles(proj, velocity_models_dict):\n        name_year_map = proj.t_indices\n        vmod = velocity_models_dict[proj.stagyy_model_names[0]][0]\n        shape = proj.geom[\"nytot\"], proj.geom[\"nztot\"]\n        z = np.reshape((1 - vmod.r) * vmod.r_E_km, shape)[0]\n\n        heterogeneity_dictionary = {}\n        for vel_model_name in name_year_map:\n            vmods = velocity_models_dict[vel_model_name]\n            t_indices = name_year_map[vel_model_name]\n\n            spr = [m.get_rprofile(\"s\")[-1] for m in vmods]\n            ppr = [m.get_rprofile(\"p\")[-1] for m in vmods]\n            rho = [m.get_rprofile(\"rho\")[-1] for m in vmods]\n            b = [m.bulk.reshape(shape) for m in vmods]\n            prim = [m.C[-1].reshape(shape) for m in vmods]\n            T = [m.T.reshape(shape) for m in vmods]\n            T_a = [m.anomaly(\"T\")[0].reshape(shape) for m in vmods]\n            s = [m.s.reshape(shape) for m in vmods]\n            p = [m.p.reshape(shape) for m in vmods]\n            s_a = [m.anomaly(\"s\")[0].reshape(shape) for m in vmods]\n            p_a = [m.anomaly(\"p\")[0].reshape(shape) for m in vmods]\n            b_a = [m.anomaly(\"bulk\")[0].reshape(shape) for m in vmods]\n\n            s_lim = 0.4\n            p_lim = 0.2\n            s_safe = [np.ma.masked_array(x, np.abs(x) &lt; s_lim) for x in s_a]\n            p_safe = [np.ma.masked_array(x, np.abs(x) &lt; p_lim) for x in p_a]\n            s_safe = [\n                np.ma.masked_array(x, x * y &lt; 0)\n                for x, y in zip(s_safe, p_safe, strict=False)\n            ]\n            p_safe = [\n                np.ma.masked_array(y, x * y &lt; 0)\n                for x, y in zip(s_safe, p_safe, strict=False)\n            ]\n\n            r_sp = [s / p for s, p in zip(s_safe, p_safe, strict=False)]\n\n            cor_b_s = [\n                np.r_[[np.corrcoef(x[:, i], y[:, i])[0, 1] for i in range(shape[1])]]\n                for x, y in zip(b_a, s_a, strict=False)\n            ]\n\n            profiles_keys = \"s_a\", \"p_a\", \"b_a\", \"b\", \"r_sp\", \"s\", \"p\"\n            profiles = {k: {} for k in profiles_keys}\n            functions = [np.ma.mean, np.ma.median, np.ma.std, rms]\n            fnames = [\"mean\", \"median\", \"std\", \"rms\"]\n            for fun, fkey in zip(functions, fnames, strict=False):\n                for xx, key in zip(\n                    [s_a, p_a, b_a, b, r_sp, s, p], profiles_keys, strict=False\n                ):\n                    profiles[key][fkey] = [fun(x, axis=0) for x in xx]\n\n            r_sp_robust = np.ma.vstack(profiles[\"s_a\"][\"rms\"]) / np.ma.vstack(\n                profiles[\"p_a\"][\"rms\"]\n            )\n\n            hets = {\n                \"z\": z,\n                \"lims\": ({\"s_lim\": s_lim, \"p_lim\": p_lim}),\n                \"t_indices\": t_indices,\n                \"mod_name\": vel_model_name,\n                \"prim\": prim,\n                \"profs\": profiles,\n                \"s\": spr,\n                \"p\": ppr,\n                \"rho\": rho,\n                \"cor_b_s\": cor_b_s,\n                \"r_sp_robust\": r_sp_robust,\n                \"T\": T,\n                \"T_a\": T_a,\n            }\n\n            heterogeneity_dictionary[vel_model_name] = hets\n\n        return heterogeneity_dictionary\n\n    @staticmethod\n    def save_heterogeneity_dictionary(heterogeneity_dictionary, path):\n        for vname in heterogeneity_dictionary:\n            fname = f\"{path}/{vname}_het_profs.pkl\"\n            with open(fname, \"wb\") as f:\n                pickle.dump(heterogeneity_dictionary[vname], f)\n\n    @staticmethod\n    def load(project_path):\n        with open(project_path + \"project_data.pkl\", \"rb\") as f:\n            return pickle.load(f)\n</code></pre>"},{"location":"api/#chimera.chimera_project.Project.__init__","title":"<code>__init__()</code>","text":"<p>Initialize project.</p>"},{"location":"api/#chimera.chimera_project.Project.__init__--returns","title":"Returns","text":"<p>None.</p> Source code in <code>src/chimera/chimera_project.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initialize project.\n\n    Returns\n    -------\n    None.\n\n    \"\"\"\n    self.test_mode_on = False\n    self.quick_mode_on = False\n    self.custom_mesh_shape = None\n    self._GY = 3600 * 24 * 364 * 1e9  # [s]\n    self.chimera_project_path = \"\"  # path where you want to save project\n    self.bg_model = \"\"  # name of your axisem bg model\n    self.thermo_data_path = \"\"  # parent path to thermo_data files\n    self.thermo_data_names = \"\"  # their names. single str of list str\n    self.stagyy_path = \"\"  # path to your stagyy models\n    self.stagyy_model_names = []\n    self.elastic_path = \"/elastic-fields/\"\n    self.vel_model_path = \"/seism_vel-fields/\"\n    self.time_span_Gy = []  # timesteps for which you want to compute vmodel\n    self.geom = None  # geom of the geodynamic models grid (same 4 all)\n    self._regular_rect_mesh = False\n</code></pre>"},{"location":"api/#chimera.chimera_project.Project.get_mesh_xy","title":"<code>get_mesh_xy()</code>","text":"<p>Generate x and y.</p> <p>mesh_x : TYPE     DESCRIPTION. mesh_y : TYPE     DESCRIPTION.</p> Source code in <code>src/chimera/chimera_project.py</code> <pre><code>def get_mesh_xy(self):\n    \"\"\"\n    Generate x and y.\n\n    -------\n    mesh_x : TYPE\n        DESCRIPTION.\n    mesh_y : TYPE\n        DESCRIPTION.\n\n    \"\"\"\n    if self.quick_mode_on:\n        print(\"We assume all models are defined on the same grid\")\n        nm = self.stagyy_model_names[0]\n        sdat = stagyydata.StagyyData(self.stagyy_path + nm)\n        mesh_x, mesh_y = _get_mesh_xy(sdat)\n    else:\n        path_x = self.chimera_project_path + self.bg_model + \"_x.npy\"\n        path_y = self.chimera_project_path + self.bg_model + \"_y.npy\"\n        mesh_x = np.load(path_x)\n        mesh_y = np.load(path_y)\n        if self.custom_mesh_shape is not None:\n            try:\n                shp = self.custom_mesh_shape\n                np.reshape(mesh_x, shp)\n                np.reshape(mesh_y, shp)\n                self._regular_rect_mesh = True\n                msg = (\n                    \"Mesh reshaped into provided shape. \"\n                    \"Please, check quality of result.\"\n                )\n                warnings.warn(msg, stacklevel=2)\n            except ValueError:\n                self._regular_rect_mesh = False\n                self.custom_mesh_shape = None\n                msg = (\n                    \"cannot reshape mesh into provided shape.\"\n                    \"Continuing assuming non-rectangular, \"\n                    \"axisem-like mesh: custom_mesh_shape set to None.\"\n                )\n                warnings.warn(msg, stacklevel=2)\n\n    return mesh_x, mesh_y\n</code></pre>"},{"location":"api/#chimera.chimera_project.Project.new","title":"<code>new(proj_name='New Project')</code>","text":"<p>Create a new project.</p>"},{"location":"api/#chimera.chimera_project.Project.new--parameters","title":"Parameters","text":"<p>proj_name : TYPE, optional     DESCRIPTION. The default is \"New Project\".</p>"},{"location":"api/#chimera.chimera_project.Project.new--returns","title":"Returns","text":"<p>None.</p> Source code in <code>src/chimera/chimera_project.py</code> <pre><code>def new(self, proj_name=\"New Project\"):\n    \"\"\"\n    Create a new project.\n\n    Parameters\n    ----------\n    proj_name : TYPE, optional\n        DESCRIPTION. The default is \"New Project\".\n\n    Returns\n    -------\n    None.\n\n    \"\"\"\n    self.project_name = proj_name\n    parent = self.chimera_project_path + proj_name + \"/\"\n    os.mkdir(parent)\n    geoms = []\n    for nm in self.stagyy_model_names:\n        print(\"Loading\", nm)\n        path = parent + nm\n        os.mkdir(path)\n        for t in self.time_span_Gy:\n            if self.test_mode_on:\n                index = 0\n            else:\n                sdat = stagyydata.StagyyData(self.stagyy_path + nm)\n                index = sdat.snaps.at_time(t * self._GY).isnap\n                geom = sdat.par[\"geometry\"]\n            path_snap = (path + \"/%i\") % index\n            os.mkdir(path_snap)\n            os.mkdir(path_snap + self.elastic_path)\n            os.mkdir(path_snap + self.vel_model_path)\n            self.t_indices[nm].append(index)\n        geoms.append(geom)\n\n    if not np.all(np.r_[geoms] == geom):\n        msg = \"All models must share the same geometry parameters\"\n        raise NotImplementedError(msg)\n    self.geom = geoms[0]\n\n    with open(parent + \"project_data.pkl\", \"wb\") as outp:\n        pickle.dump(self, outp, pickle.HIGHEST_PROTOCOL)\n</code></pre>"},{"location":"api/#chimera.field","title":"<code>field</code>","text":""},{"location":"api/#chimera.field.Field","title":"<code>Field</code>","text":"<p>General class implementing a named field defined on a regular grid. The coordinates of the grid must be polar (r, theta).</p> Source code in <code>src/chimera/field.py</code> <pre><code>class Field:\n    \"\"\"\n    General class implementing a named field defined on a regular grid.\n    The coordinates of the grid must be polar (r, theta).\n    \"\"\"\n\n    def __init__(self, proj, name=\"T\"):\n        # TODO check order\n        # StagYY coordinates r, theta (or theta, r)\n        self._coords = (None, None)\n        # Values of StagYY field\n        self._values = None\n        # Name of Stagyy model\n        self.name = name\n        # Max radius of StagYY model (e.g. radius of Earth)\n        self.r_max = None\n        # project of reference\n        self.proj = proj\n\n    @property\n    def coords(self):\n        return self._coords\n\n    @coords.setter\n    def coords(self, value):\n        if len(value) != 2:  # noqa: PLR2004\n            msg = \"Coords must be a 2-elements tuple.\"\n            raise TypeError(msg)\n        self._coords = value\n\n    @property\n    def values(self):\n        return self._values\n\n    @values.setter\n    def values(self, value):\n        self._values = value\n\n    @property\n    def polar(self):\n        return self._polar\n\n    @polar.setter\n    def polar(self, value):\n        self._polar = value\n\n    def to_cartesian(self):\n        \"\"\"\n\n\n        Returns\n        -------\n        TYPE tuple of two numpy.array.\n            (x, y). The coordinates are unraveled.\n            len(x) = len(y) = len(r) * len(theta) = self.values.size\n\n        \"\"\"\n        r_grid, theta_grid = np.meshgrid(*self.coords)\n        z = r_grid * np.exp(1j * theta_grid)\n        x, y = np.real(z).flatten(), np.imag(z).flatten()\n        return x, y\n\n    # TODO remove split, because you need both halves actually. AxiSEM rotates.\n    def split(self, edge_pad_perc=0.25):\n        \"\"\"\n        Splits the model in two portions (a left one and right one).\n        This is needed, as the axisem grid is only half of the whole \"annulus\".\n        Using edge_extension_perc it is possible to pad and include more points\n        from boht sides of the halved field. This is useful when interpolating\n        on the final fine grid.\n\n        Parameters\n        ----------\n        edge_pad_perc : float\n            Extent of the padding, given as a percentage of the half-length of\n            self.values. The number of indices to get from each side of the\n            half-annulus is int(edge_pad_perc * self.values.shape[0] // 2).\n\n        Returns\n        -------\n        fields : list of 2 objects of type(self)\n            The two portions of the stagyy field: [left, right].\n\n        \"\"\"\n        # I divide in half\n        nth_2 = self.values.shape[0] // 2\n        # then i take a portion of that half defined by my percentage\n        dx_2 = int(edge_pad_perc * nth_2)\n        # the stuff that's on top appears at the bottom and viceversa\n        left_half = np.roll(self.values, -dx_2, axis=0)[nth_2 - 2 * dx_2 :]\n        right_half = np.roll(self.values, dx_2, axis=0)[: nth_2 + 2 * dx_2]\n        r, theta = self.coords\n        # I need to decide whether I want to tak that from the existing\n        # attributes or if I want to recreate them\n        theta_r = np.roll(theta, -dx_2)[nth_2 - 2 * dx_2 :]\n        theta_l = np.roll(theta, dx_2)[: nth_2 + 2 * dx_2]\n        fields = [Field(), Field()]\n        for fld, half, coord in zip(\n            fields, [left_half, right_half], [(r, theta_l), (r, theta_r)], strict=False\n        ):\n            fld.values = half\n            fld.coords = coord\n\n        return fields\n\n    def normalize_radius(self):\n        self.r_max = self.coords[0].max()\n        self._coords = self.coords[0] / self.r_max, self.coords[1]\n\n    def interpolate(self, interp_type, xnew, ynew):\n        # - if you want to use the orig stag grid, just return the orig array\n        # - if you want to use another mesh, you must have provided it\n        # -- if it's a rectangular grid (only if the shape was provided!)\n        # ---- we need to check if it is a coarser grid or not (in the former\n        # ---- case, appropriate antialiasing filtering is needed first)\n        # ---- else, simply interpolate\n        # -- if it's not a rectangular grid (or could not reshape it into\n        # -- the provided shape, or no shape was provided [e.g. axisem case])\n        # -- simply interpolate\n\n        z = self.values.flatten()\n        if self.proj.quick_mode_on:\n            interpolated = z\n        else:\n            self.normalize_radius()\n            x, y = self.to_cartesian()\n            old = np.c_[x, y]\n            new = np.c_[xnew, ynew]\n            if self.proj._regular_rect_mesh:  # noqa: SLF001\n                r = self.coords[0]\n                theta = self.coords[1]\n                rnew, thetanew = to_polar(xnew, ynew)\n                rnew = rnew.reshape(self.proj.custom_mesh_shape)[0]\n                thetanew = thetanew.reshape(self.proj.custom_mesh_shape)[:, 0]\n                x_is_coarse = np.abs(np.diff(r).min()) &lt; np.abs(np.diff(rnew).min())\n                y_is_coarse = np.abs(np.diff(theta).min()) &lt; np.abs(\n                    np.diff(thetanew).min()\n                )\n                if x_is_coarse or y_is_coarse:\n                    downsampler = Downsampler(r, theta, rnew, thetanew)\n                    old, z = downsampler.downsample(z)\n                    z = z.flatten()\n                    interp_type = \"nearest\"\n                    # HACK distinction necessary: the downsampler also gives\n                    # me the coordinates, it means that the method used was\n                    # filtering and the output array must actually be sampled\n                    # otherwise, the result is already sampled\n                    # In the future I will pick one method and delete this if\n                    if old is not None:\n                        interpolated = griddata(old, z, new, method=interp_type)\n                    else:\n                        interpolated = z\n                else:\n                    interpolated = griddata(old, z, new, method=interp_type)\n            else:\n                interpolated = griddata(old, z, new, method=interp_type)\n\n        return interpolated\n\n    def plot(self):\n        fig = plt.figure()\n        ax = fig.gca()\n        x, y = self.to_cartesian()\n        z = self.values.flatten()\n        ax.tricontourf(x, y, z, levels=256)\n        return fig, ax\n</code></pre>"},{"location":"api/#chimera.field.Field.split","title":"<code>split(edge_pad_perc=0.25)</code>","text":"<p>Splits the model in two portions (a left one and right one). This is needed, as the axisem grid is only half of the whole \"annulus\". Using edge_extension_perc it is possible to pad and include more points from boht sides of the halved field. This is useful when interpolating on the final fine grid.</p>"},{"location":"api/#chimera.field.Field.split--parameters","title":"Parameters","text":"<p>edge_pad_perc : float     Extent of the padding, given as a percentage of the half-length of     self.values. The number of indices to get from each side of the     half-annulus is int(edge_pad_perc * self.values.shape[0] // 2).</p>"},{"location":"api/#chimera.field.Field.split--returns","title":"Returns","text":"<p>fields : list of 2 objects of type(self)     The two portions of the stagyy field: [left, right].</p> Source code in <code>src/chimera/field.py</code> <pre><code>def split(self, edge_pad_perc=0.25):\n    \"\"\"\n    Splits the model in two portions (a left one and right one).\n    This is needed, as the axisem grid is only half of the whole \"annulus\".\n    Using edge_extension_perc it is possible to pad and include more points\n    from boht sides of the halved field. This is useful when interpolating\n    on the final fine grid.\n\n    Parameters\n    ----------\n    edge_pad_perc : float\n        Extent of the padding, given as a percentage of the half-length of\n        self.values. The number of indices to get from each side of the\n        half-annulus is int(edge_pad_perc * self.values.shape[0] // 2).\n\n    Returns\n    -------\n    fields : list of 2 objects of type(self)\n        The two portions of the stagyy field: [left, right].\n\n    \"\"\"\n    # I divide in half\n    nth_2 = self.values.shape[0] // 2\n    # then i take a portion of that half defined by my percentage\n    dx_2 = int(edge_pad_perc * nth_2)\n    # the stuff that's on top appears at the bottom and viceversa\n    left_half = np.roll(self.values, -dx_2, axis=0)[nth_2 - 2 * dx_2 :]\n    right_half = np.roll(self.values, dx_2, axis=0)[: nth_2 + 2 * dx_2]\n    r, theta = self.coords\n    # I need to decide whether I want to tak that from the existing\n    # attributes or if I want to recreate them\n    theta_r = np.roll(theta, -dx_2)[nth_2 - 2 * dx_2 :]\n    theta_l = np.roll(theta, dx_2)[: nth_2 + 2 * dx_2]\n    fields = [Field(), Field()]\n    for fld, half, coord in zip(\n        fields, [left_half, right_half], [(r, theta_l), (r, theta_r)], strict=False\n    ):\n        fld.values = half\n        fld.coords = coord\n\n    return fields\n</code></pre>"},{"location":"api/#chimera.field.Field.to_cartesian","title":"<code>to_cartesian()</code>","text":""},{"location":"api/#chimera.field.Field.to_cartesian--returns","title":"Returns","text":"<p>TYPE tuple of two numpy.array.     (x, y). The coordinates are unraveled.     len(x) = len(y) = len(r) * len(theta) = self.values.size</p> Source code in <code>src/chimera/field.py</code> <pre><code>def to_cartesian(self):\n    \"\"\"\n\n\n    Returns\n    -------\n    TYPE tuple of two numpy.array.\n        (x, y). The coordinates are unraveled.\n        len(x) = len(y) = len(r) * len(theta) = self.values.size\n\n    \"\"\"\n    r_grid, theta_grid = np.meshgrid(*self.coords)\n    z = r_grid * np.exp(1j * theta_grid)\n    x, y = np.real(z).flatten(), np.imag(z).flatten()\n    return x, y\n</code></pre>"},{"location":"api/#chimera.functions","title":"<code>functions</code>","text":""},{"location":"api/#chimera.functions.compute_vmodels","title":"<code>compute_vmodels(proj, use_stagyy_rho=False)</code>","text":""},{"location":"api/#chimera.functions.compute_vmodels--parameters","title":"Parameters","text":"<p>proj : class Proj     Your chimera project, from which all relevant information is taken. use_stagyy_rho : bool, optional     Uses stagyy density instead of that obtained via Perple_X.     The default is False.</p>"},{"location":"api/#chimera.functions.compute_vmodels--returns","title":"Returns","text":"<p>v_model_paths : TYPE     DESCRIPTION.</p> Source code in <code>src/chimera/functions.py</code> <pre><code>def compute_vmodels(proj, use_stagyy_rho=False):\n    \"\"\"\n\n\n    Parameters\n    ----------\n    proj : class Proj\n        Your chimera project, from which all relevant information is taken.\n    use_stagyy_rho : bool, optional\n        Uses stagyy density instead of that obtained via Perple_X.\n        The default is False.\n\n    Returns\n    -------\n    v_model_paths : TYPE\n        DESCRIPTION.\n\n    \"\"\"\n    v_model_paths = []\n    zip_names = zip(proj.stagyy_model_names, proj.thermo_data_names, strict=False)\n    for count, (model_name, thermo_name) in enumerate(zip_names):\n        thermo_path = proj.thermo_data_path + thermo_name\n        parent_path = proj.chimera_project_path + proj.project_name + \"/\"\n        model_path = parent_path + model_name\n\n        print(\"Loading velocity models obtained from\", model_path)\n        indices, years = proj.t_indices[model_name], proj.time_span_Gy\n        print(\"using the perplex tables saved as \", thermo_path)\n        print(\n            \"for each of time steps in\", years, \"Gy, corresponding to indices\", indices\n        )\n        print()\n\n        thermodata = ThermoData.load(thermo_path)\n        for i_t, _t in zip(indices, years, strict=False):\n            snap_path = model_path + f\"/{i_t}/\"\n            v_path = snap_path + proj.vel_model_path\n            print(\"Loading velocity model saved in\", v_path)\n            v_model = VelocityModel.load(v_path)\n\n            moduli_location = snap_path + proj.elastic_path\n            print(\"Averaging rho, K, G\")\n            v_model.average(\n                *v_model.load_moduli(moduli_location, thermodata.proj_names_dict)\n            )\n\n            print(\"Computing seismic velocities\")\n            v_model.compute_velocities(use_stagyy_rho)\n            print(\"Overwriting velocity model saved in\", v_path)\n            v_model_paths.append(v_path)\n            v_model.save(v_path)\n\n            print(\"Done\")\n            print(\"-\" * 76)\n\n        print(\"%i/%i models done\" % (count, len(proj.stagyy_model_names)))\n        print(\"+\" * 76)\n    return v_model_paths\n</code></pre>"},{"location":"api/#chimera.functions.export_vmodels","title":"<code>export_vmodels(proj, absolute=True, fac=100, fmt='%.2f', dtype='float32', fname='geodynamic_hetfile.sph')</code>","text":""},{"location":"api/#chimera.functions.export_vmodels--parameters","title":"Parameters","text":"<p>proj : TYPE     DESCRIPTION. absolute : TYPE, optional     DESCRIPTION. The default is True. fac : TYPE, optional     DESCRIPTION. The default is 100. fmt : TYPE, optional     DESCRIPTION. The default is \"%.2f\". dtype : TYPE, optional     DESCRIPTION. The default is \"float32\". fname : TYPE, optional     DESCRIPTION. The default is \"geodynamic_hetfile.sph\".</p>"},{"location":"api/#chimera.functions.export_vmodels--returns","title":"Returns","text":"<p>None.</p> Source code in <code>src/chimera/functions.py</code> <pre><code>def export_vmodels(\n    proj,\n    absolute=True,\n    fac=100,\n    fmt=\"%.2f\",\n    dtype=\"float32\",\n    fname=\"geodynamic_hetfile.sph\",\n):\n    \"\"\"\n\n    Parameters\n    ----------\n    proj : TYPE\n        DESCRIPTION.\n    absolute : TYPE, optional\n        DESCRIPTION. The default is True.\n    fac : TYPE, optional\n        DESCRIPTION. The default is 100.\n    fmt : TYPE, optional\n        DESCRIPTION. The default is \"%.2f\".\n    dtype : TYPE, optional\n        DESCRIPTION. The default is \"float32\".\n    fname : TYPE, optional\n        DESCRIPTION. The default is \"geodynamic_hetfile.sph\".\n\n    Returns\n    -------\n    None.\n\n    \"\"\"\n    for model_name in proj.stagyy_model_names:\n        parent_path = proj.chimera_project_path + proj.project_name + \"/\"\n        model_path = parent_path + model_name\n        print(\"Loading velocity models from\", model_path)\n        indices, years = proj.t_indices[model_name], proj.time_span_Gy\n        print(\n            \"for each of time steps in\", years, \"Gy, corresponding to indices\", indices\n        )\n        print()\n        for i_t, _t in zip(indices, years, strict=False):\n            snap_path = model_path + f\"/{i_t}/\"\n            v_path = snap_path + proj.vel_model_path\n            print(\"Loading velocity model saved in\", v_path)\n            v_model = VelocityModel.load(v_path)\n            print(\"Exporting to {} format\".format(fname.rsplit(\".\")[-1]))\n            v_model.export(v_path, fmt, absolute, fac, fname, dtype)\n            print(\"Done\")\n            print(\"----------------------------------------------------------\")\n            print()\n</code></pre>"},{"location":"api/#chimera.functions.geodynamic_to_thermoelastic","title":"<code>geodynamic_to_thermoelastic(proj)</code>","text":""},{"location":"api/#chimera.functions.geodynamic_to_thermoelastic--parameters","title":"Parameters","text":"<p>proj : TYPE     DESCRIPTION.</p>"},{"location":"api/#chimera.functions.geodynamic_to_thermoelastic--returns","title":"Returns","text":"<p>None.</p> Source code in <code>src/chimera/functions.py</code> <pre><code>def geodynamic_to_thermoelastic(proj):\n    \"\"\"\n\n\n    Parameters\n    ----------\n    proj : TYPE\n        DESCRIPTION.\n\n    Returns\n    -------\n    None.\n\n    \"\"\"\n    zip_names = zip(proj.stagyy_model_names, proj.thermo_data_names, strict=False)\n    # in principle, there might be a different thermo data set 4 each model\n    if _all_equals(proj.thermo_data_names):\n        print(\"The same thermodynamic dataset was assigned to all models\")\n        _thermodata = ThermoData.load(proj.thermo_data_path + proj.thermo_data_names[0])\n        _tree = ThermoElasticField.get_tree(_thermodata.tabs[0])\n    else:\n        _tree, _thermodata = None, None\n\n    for model_name, thermo_name in zip_names:\n        parent_path = proj.chimera_project_path + proj.project_name + \"/\"\n        model_path = parent_path + model_name\n        print(\"Compute thermoelastic properties for the geodynamic model:\")\n        print(model_path)\n        print(\"which uses the thermodynamic data saved as:\")\n        print(proj.thermo_data_path + thermo_name)\n        print()\n        indices, years = proj.t_indices[model_name], proj.time_span_Gy\n        print(\"Time steps: \", years, \"Gy, corresponding to indices\", indices)\n        print()\n\n        if _thermodata is _tree is None:\n            thermodata = ThermoData.load(proj.thermo_data_path + thermo_name)\n            tree = ThermoElasticField.get_tree(thermodata.tabs[0])\n        else:\n            thermodata = _thermodata\n            tree = _tree\n\n        for i_t, _t in zip(indices, years, strict=False):\n            snap_path = model_path + f\"/{i_t}/\"\n            v_path = snap_path + proj.vel_model_path\n            v_model = VelocityModel.load(v_path)\n            save_path = snap_path + proj.elastic_path\n\n            # checking if there is anything missing\n            all_exist = _check_all_exist(thermodata, save_path)\n\n            if not all_exist:\n                print(\"Loading P, T from velocity model saved in\\n\", v_path)\n                T, P = v_model.T, v_model.P\n                inds = ThermoElasticField.get_indices(tree, T, P)\n                for tab, f in zip(\n                    thermodata.tabs, thermodata.c_field_names[0], strict=False\n                ):\n                    print(f\"... working on {f} ...\")\n                    thermo_field = ThermoElasticField(tab, f)\n                    thermo_field.extract(inds, model_name)\n                    thermo_field.save(save_path)\n            else:\n                print(\n                    \"It looks like everything was already done for\",\n                    \"this model at time step %i.\" % i_t,\n                )\n\n            print(\"Done\")\n            print(\"-\" * 76)\n        print(\"+\" * 76)\n</code></pre>"},{"location":"api/#chimera.interfaces","title":"<code>interfaces</code>","text":""},{"location":"api/#chimera.interfaces.axi","title":"<code>axi</code>","text":""},{"location":"api/#chimera.interfaces.axi.inparam_hetero_template","title":"<code>inparam_hetero_template</code>","text":"<p>Created on Thu Sep 15 16:39:26 2022.</p> <p>@author: matteo</p>"},{"location":"api/#chimera.interfaces.axi.mesh_importer","title":"<code>mesh_importer</code>","text":"<p>Created on Wed Jun  8 18:31:11 2022.</p> <p>@author: matteo</p>"},{"location":"api/#chimera.interfaces.axi.mesh_importer.MeshImporter","title":"<code>MeshImporter</code>","text":"<p>Load, convert and save an AxiSEM mesh as a numpy array.</p>"},{"location":"api/#chimera.interfaces.axi.mesh_importer.MeshImporter--arguments","title":"Arguments:","text":"<p>axisem_path : str     The AxiSEM directory mesh_path : str     The name of the mesh stored in the SOLVER directory.     The default is \"PREM_ISO_2s\"</p> Source code in <code>src/chimera/interfaces/axi/mesh_importer.py</code> <pre><code>class MeshImporter:\n    \"\"\"\n\n    Load, convert and save an AxiSEM mesh as a numpy array.\n\n    Arguments:\n    ---------\n    axisem_path : str\n        The AxiSEM directory\n    mesh_path : str\n        The name of the mesh stored in the SOLVER directory.\n        The default is \"PREM_ISO_2s\"\n\n    \"\"\"\n\n    def __init__(\n        self, axisem_path, mesh_path=\"PREM_ISO_2s\", rE_km=6371.0, dtype=\"float32\"\n    ):\n        self.dtype = dtype\n        self.axisem_path = axisem_path\n        self.mesh_name = mesh_path\n        self.x, self.y = self.loader()\n        # for now this is set maually. TODO: read this from inparam_mesh\n        self.rE_km = rE_km  # radius of the planet\n\n    def loader(self):\n        \"\"\"\n        Convert an AxiSEM vtk mesh into a numpy npy file.\n\n        Returns\n        -------\n        x, y : numpy.ndarray\n            Cordinates of the central points of the cells of the AxiSEM mesh.\n\n        \"\"\"\n        reader = vtk.vtkGenericDataObjectReader()\n        _vtkname = \"mesh_domaindecomposition.vtk\"\n        path = self.axisem_path + \"/SOLVER/MESHES/\" + self.mesh_name + \"/\"\n        os.chdir(path)\n        reader.SetFileName(_vtkname)\n        reader.Update()\n        points = reader.GetOutput().GetPoints()\n        data_type = points.GetDataType()\n        # TODO raise an error if choice is not consistent\n        # or better, load directly in double precision\n        print(\n            \"The data_type of the vtk points is %i.\" % data_type,\n            \"Double-check if consistent with your choice of\",\n            self.dtype,\n        )\n        x, y = np.array(points.GetData(), dtype=self.dtype)[:, :-1].T\n        return x, y\n\n    def convert_to_numpy(self, path, autoname=True, r_core_km=3480.5):\n        \"\"\"\n        Save the mesh as an array.\n\n        Parameters\n        ----------\n        path : str\n            path to where the points array is saved.\n        autoname : bool, optional\n            If True the name of the .npy file is the same as the mesh name\n            given by AxiSEM. Else, it can be specified. The default is True.\n        r_core_km : float, optional\n            The core radius in km. All points falling inside this radius will\n            not be saved. The default is 3480.5\n\n        Returns\n        -------\n        out : ndarray\n            An array object with the coordinates of the central points of the\n            AxiSEM mesh. First and second col are x and y coordinates,\n            respectively. Note that the AxiSEM grid (corresponding to\n            a half-circle) is mirrored around the axis to form a complete\n            circle. This array is also saved in the specified path.\n\n        \"\"\"\n        if autoname:\n            path += \"/\" + self.mesh_name\n\n        ratio = r_core_km / self.rE_km  # the axi grid is normalized to R_surf\n        mantle = np.hypot(self.x, self.y) &gt; ratio\n        _x, _y = self.x[mantle], self.y[mantle]\n        # notice mirrored data\n        np.save(path + \"_x\", np.r_[_x, -_x])\n        np.save(path + \"_y\", np.r_[_y, _y])\n        return np.r_[_x, -_x], np.r_[_y, _y]\n</code></pre>"},{"location":"api/#chimera.interfaces.axi.mesh_importer.MeshImporter.convert_to_numpy","title":"<code>convert_to_numpy(path, autoname=True, r_core_km=3480.5)</code>","text":"<p>Save the mesh as an array.</p>"},{"location":"api/#chimera.interfaces.axi.mesh_importer.MeshImporter.convert_to_numpy--parameters","title":"Parameters","text":"<p>path : str     path to where the points array is saved. autoname : bool, optional     If True the name of the .npy file is the same as the mesh name     given by AxiSEM. Else, it can be specified. The default is True. r_core_km : float, optional     The core radius in km. All points falling inside this radius will     not be saved. The default is 3480.5</p>"},{"location":"api/#chimera.interfaces.axi.mesh_importer.MeshImporter.convert_to_numpy--returns","title":"Returns","text":"<p>out : ndarray     An array object with the coordinates of the central points of the     AxiSEM mesh. First and second col are x and y coordinates,     respectively. Note that the AxiSEM grid (corresponding to     a half-circle) is mirrored around the axis to form a complete     circle. This array is also saved in the specified path.</p> Source code in <code>src/chimera/interfaces/axi/mesh_importer.py</code> <pre><code>def convert_to_numpy(self, path, autoname=True, r_core_km=3480.5):\n    \"\"\"\n    Save the mesh as an array.\n\n    Parameters\n    ----------\n    path : str\n        path to where the points array is saved.\n    autoname : bool, optional\n        If True the name of the .npy file is the same as the mesh name\n        given by AxiSEM. Else, it can be specified. The default is True.\n    r_core_km : float, optional\n        The core radius in km. All points falling inside this radius will\n        not be saved. The default is 3480.5\n\n    Returns\n    -------\n    out : ndarray\n        An array object with the coordinates of the central points of the\n        AxiSEM mesh. First and second col are x and y coordinates,\n        respectively. Note that the AxiSEM grid (corresponding to\n        a half-circle) is mirrored around the axis to form a complete\n        circle. This array is also saved in the specified path.\n\n    \"\"\"\n    if autoname:\n        path += \"/\" + self.mesh_name\n\n    ratio = r_core_km / self.rE_km  # the axi grid is normalized to R_surf\n    mantle = np.hypot(self.x, self.y) &gt; ratio\n    _x, _y = self.x[mantle], self.y[mantle]\n    # notice mirrored data\n    np.save(path + \"_x\", np.r_[_x, -_x])\n    np.save(path + \"_y\", np.r_[_y, _y])\n    return np.r_[_x, -_x], np.r_[_y, _y]\n</code></pre>"},{"location":"api/#chimera.interfaces.axi.mesh_importer.MeshImporter.loader","title":"<code>loader()</code>","text":"<p>Convert an AxiSEM vtk mesh into a numpy npy file.</p>"},{"location":"api/#chimera.interfaces.axi.mesh_importer.MeshImporter.loader--returns","title":"Returns","text":"<p>x, y : numpy.ndarray     Cordinates of the central points of the cells of the AxiSEM mesh.</p> Source code in <code>src/chimera/interfaces/axi/mesh_importer.py</code> <pre><code>def loader(self):\n    \"\"\"\n    Convert an AxiSEM vtk mesh into a numpy npy file.\n\n    Returns\n    -------\n    x, y : numpy.ndarray\n        Cordinates of the central points of the cells of the AxiSEM mesh.\n\n    \"\"\"\n    reader = vtk.vtkGenericDataObjectReader()\n    _vtkname = \"mesh_domaindecomposition.vtk\"\n    path = self.axisem_path + \"/SOLVER/MESHES/\" + self.mesh_name + \"/\"\n    os.chdir(path)\n    reader.SetFileName(_vtkname)\n    reader.Update()\n    points = reader.GetOutput().GetPoints()\n    data_type = points.GetDataType()\n    # TODO raise an error if choice is not consistent\n    # or better, load directly in double precision\n    print(\n        \"The data_type of the vtk points is %i.\" % data_type,\n        \"Double-check if consistent with your choice of\",\n        self.dtype,\n    )\n    x, y = np.array(points.GetData(), dtype=self.dtype)[:, :-1].T\n    return x, y\n</code></pre>"},{"location":"api/#chimera.interfaces.perp","title":"<code>perp</code>","text":""},{"location":"api/#chimera.interfaces.perp.tab","title":"<code>tab</code>","text":""},{"location":"api/#chimera.interfaces.perp.tab.Tab","title":"<code>Tab</code>","text":"Source code in <code>src/chimera/interfaces/perp/tab.py</code> <pre><code>class Tab:\n    def __init__(self, inpfl):\n        self.inpfl = inpfl\n        self.tab = {}\n        with open(inpfl) as fl:\n            _ = fl.readline().strip()  # skip line..\n            title = fl.readline().strip()  # remove blanks...\n            _ = fl.readline().strip()\n            _ = fl.readline().strip()\n            _ = fl.readline().strip()\n            dT = float(fl.readline())\n            nT = float(fl.readline())\n            _ = fl.readline().strip()\n            _ = fl.readline().strip()\n            dP = float(fl.readline())\n            nP = float(fl.readline())\n            nvar = float(fl.readline())\n            variables = fl.readline()\n\n        nT, nP, nvar = int(nT), int(nP), int(nvar)\n\n        # read actual data\n        print(\"\\nReading table:  \" + title)\n\n        fields = variables.split()\n        self.tab[\"title\"] = \"\".join(title.split(\".\")[:-1])\n        self.tab[\"dT\"] = dT\n        self.tab[\"dP\"] = dP\n        self.tab[\"nT\"] = nT\n        self.tab[\"nP\"] = nP\n        self.tab[\"nvar\"] = nvar\n        self.tab[\"fields\"] = fields\n\n        print(\"dT: \", dT, \", dP: \", dP, \", nT: \", nT, \", nP: \", nP, \", nvar: \", nvar)\n        self.data = []  # could parallelize method, but need 2 initialize data\n\n    def load(self):\n        nT = self.tab[\"nT\"]\n        nP = self.tab[\"nP\"]\n        for i, field in enumerate(self.tab[\"fields\"]):\n            data_ = np.loadtxt(self.inpfl, skiprows=13, usecols=i)\n            if field == \"T(K)\":\n                data_ = data_[:nT]\n\n            elif field == \"P(bar)\":\n                data_ = data_[::nT]\n\n            else:\n                data_ = np.reshape(data_, (nP, nT)).T\n\n            self.data.append(data_)\n\n    def save(self):\n        for i, field in enumerate(self.tab[\"fields\"]):\n            data_ = self.data[i]\n            print(\"\\nSaving table to: \" + self.tab[\"title\"] + \".npy\\n\")\n            template = \"table_{}_{}.npy\"\n            np.save(template.format(self.tab[\"title\"], field), data_)\n\n        fname = \"stats_{}.pkl\".format(self.tab[\"title\"])\n        with open(fname, \"wb\") as f:\n            pickle.dump(self.tab, f)\n\n    def plot(self, i_field, ax=None, exclude_range=None, kwargs=None):\n        if kwargs is None:\n            kwargs = {}\n        i_field = _fix_i_field(i_field)\n\n        if ax is not None:\n            fig = ax.get_figure()\n        else:\n            fig, ax = plt.subplots(1)\n\n        fld_name = self.tab[\"fields\"][i_field]\n        data = self.data[i_field]\n        T, P = self.data[:2]\n        # plotting\n        arg_given = exclude_range is not None\n        is_modulus = \"Ks\" in fld_name or \"Gs\" in fld_name\n        if arg_given and is_modulus:\n            Tmin, Tmax = exclude_range[0]\n            Pmin, Pmax = exclude_range[1]\n            TT, PP = np.meshgrid(T, P)\n            i1 = (Tmin &lt;= TT) &amp; (Tmax &gt;= TT)\n            i2 = (Pmin &lt;= PP) &amp; (Pmax &gt;= PP)\n            data_ininterval = ma.masked_array(data, i1.T &amp; i2.T)\n            vmin, vmax = data_ininterval.min(), data_ininterval.max()\n        else:\n            vmin, vmax = None, None\n\n        if \"vmin\" not in kwargs:\n            kwargs[\"vmin\"] = vmin\n        if \"vmax\" not in kwargs:\n            kwargs[\"vmax\"] = vmax\n        img = ax.pcolormesh(T, P, data.T, **kwargs)\n        ax.set_title(self.tab[\"title\"], loc=\"left\")\n        ax.set_title(self.tab[\"fields\"][i_field], loc=\"right\")\n        ax.set_ylabel(self.tab[\"fields\"][1])\n        ax.set_xlabel(self.tab[\"fields\"][0])\n        plt.colorbar(img, ax=ax)\n\n        return fig, ax\n\n    def get_contour_TP(self, i_field, T, P):\n        \"\"\"\n\n\n        Parameters\n        ----------\n        i_field : TYPE\n            DESCRIPTION.\n        T : TYPE\n            DESCRIPTION.\n        P : TYPE\n            In Pa.\n\n        Returns\n        -------\n        profile : TYPE\n            DESCRIPTION.\n\n        \"\"\"\n        i_field = _fix_i_field(i_field)\n        data = self.data[i_field]\n        Tax, Pax = self.data[:2]\n        profile = np.zeros_like(T)\n\n        for i, (T_, P_) in enumerate(zip(T, P, strict=False)):\n            iT = np.argmin(np.abs(T_ - Tax))\n            iP = np.argmin(np.abs(P_ - Pax * 1e5))\n            profile[i] = data[iT, iP]\n\n        return profile\n\n    def plot_contour_TP(self):\n        pass\n\n    def remove_nans(self):\n        for k, (f, n) in enumerate(zip(self.data, self.tab[\"fields\"], strict=False)):\n            if n not in (\"T(K)\", \"P(bar)\"):\n                new = np.array(f)\n                for where in np.argwhere(np.isnan(f)):\n                    i, j = where\n                    new[i, j] = _interp_nans(f, i, j)\n                self.data[k] = new\n</code></pre>"},{"location":"api/#chimera.interfaces.perp.tab.Tab.get_contour_TP","title":"<code>get_contour_TP(i_field, T, P)</code>","text":""},{"location":"api/#chimera.interfaces.perp.tab.Tab.get_contour_TP--parameters","title":"Parameters","text":"<p>i_field : TYPE     DESCRIPTION. T : TYPE     DESCRIPTION. P : TYPE     In Pa.</p>"},{"location":"api/#chimera.interfaces.perp.tab.Tab.get_contour_TP--returns","title":"Returns","text":"<p>profile : TYPE     DESCRIPTION.</p> Source code in <code>src/chimera/interfaces/perp/tab.py</code> <pre><code>def get_contour_TP(self, i_field, T, P):\n    \"\"\"\n\n\n    Parameters\n    ----------\n    i_field : TYPE\n        DESCRIPTION.\n    T : TYPE\n        DESCRIPTION.\n    P : TYPE\n        In Pa.\n\n    Returns\n    -------\n    profile : TYPE\n        DESCRIPTION.\n\n    \"\"\"\n    i_field = _fix_i_field(i_field)\n    data = self.data[i_field]\n    Tax, Pax = self.data[:2]\n    profile = np.zeros_like(T)\n\n    for i, (T_, P_) in enumerate(zip(T, P, strict=False)):\n        iT = np.argmin(np.abs(T_ - Tax))\n        iP = np.argmin(np.abs(P_ - Pax * 1e5))\n        profile[i] = data[iT, iP]\n\n    return profile\n</code></pre>"},{"location":"api/#chimera.interfaces.perp.thermo_elastic_field","title":"<code>thermo_elastic_field</code>","text":""},{"location":"api/#chimera.interfaces.perp.thermo_elastic_field.ThermoElasticField","title":"<code>ThermoElasticField</code>","text":"Source code in <code>src/chimera/interfaces/perp/thermo_elastic_field.py</code> <pre><code>class ThermoElasticField:\n    def __init__(self, tab=None, label=None):\n        self.tab = tab\n        self.label = label if label is not None else tab.tab[\"title\"]\n        self.rho = None\n        self.K = None\n        self.G = None\n\n    def extract(self, inds, model_name):  # noqa: ARG002\n        \"\"\"\n\n\n        Parameters\n        ----------\n        inds : TYPE\n            DESCRIPTION.\n        model_name : TYPE\n            DESCRIPTION.\n\n        Returns\n        -------\n        None.\n\n        \"\"\"\n        rho, K, G = self.tab.data[2:]\n\n        self.rho = _store(inds, rho.T.flatten())\n        self.K = _store(inds, K.T.flatten())\n        self.G = _store(inds, G.T.flatten())\n\n    def save(self, path):\n        fname = path + self.tab.tab[\"title\"] + \"_\"\n        print(f\"Saving as {fname}&lt;parameter&gt;.npy\")\n        np.save(fname + \"rho\", self.rho)\n        np.save(fname + \"K\", self.K)\n        np.save(fname + \"G\", self.G)\n        print(\"Done for rho [kg/m^3], Ks [bar], Gs [bar]\")\n\n    @staticmethod\n    def get_tree(tab):\n        \"\"\"\n\n\n        Parameters\n        ----------\n        tab : TYPE\n            DESCRIPTION.\n\n        Returns\n        -------\n        kdtree : TYPE\n            DESCRIPTION.\n\n        \"\"\"\n        print(\"Creating a tree out of the P, T range of the thermodynamic\", \"dataset\")\n        T, P = tab.data[:2]\n        # since stagyy is in Pa, convert P [bar]-&gt;[Pa])\n        P *= 1e5\n        x, y = _TP_to_xy(T, P)\n        kdtree = KDTree(np.c_[x, y], leafsize=10)\n        print(\"KDTree Created\")\n        return kdtree\n\n    @staticmethod\n    def get_indices(tree, T_grid, P_grid):\n        \"\"\"\n\n\n        Parameters\n        ----------\n        tree : TYPE\n            DESCRIPTION.\n        T_grid : TYPE\n            DESCRIPTION.\n        P_grid : TYPE\n            DESCRIPTION.\n\n        Returns\n        -------\n        inds : TYPE\n            DESCRIPTION.\n\n        \"\"\"\n        print(\"Retrieving moduli, density as function of P, T\")\n        # _,inds=tree.query(np.c_[T_grid,P_grid]) # changed with v0.1.6 # noqa: ERA001\n        # number of valid neighbors is returned too now. Must be ignored\n        _, inds, _ = tree.query(np.c_[T_grid, P_grid])\n        print(\"KDTree queried\")\n        return inds\n</code></pre>"},{"location":"api/#chimera.interfaces.perp.thermo_elastic_field.ThermoElasticField.extract","title":"<code>extract(inds, model_name)</code>","text":""},{"location":"api/#chimera.interfaces.perp.thermo_elastic_field.ThermoElasticField.extract--parameters","title":"Parameters","text":"<p>inds : TYPE     DESCRIPTION. model_name : TYPE     DESCRIPTION.</p>"},{"location":"api/#chimera.interfaces.perp.thermo_elastic_field.ThermoElasticField.extract--returns","title":"Returns","text":"<p>None.</p> Source code in <code>src/chimera/interfaces/perp/thermo_elastic_field.py</code> <pre><code>def extract(self, inds, model_name):  # noqa: ARG002\n    \"\"\"\n\n\n    Parameters\n    ----------\n    inds : TYPE\n        DESCRIPTION.\n    model_name : TYPE\n        DESCRIPTION.\n\n    Returns\n    -------\n    None.\n\n    \"\"\"\n    rho, K, G = self.tab.data[2:]\n\n    self.rho = _store(inds, rho.T.flatten())\n    self.K = _store(inds, K.T.flatten())\n    self.G = _store(inds, G.T.flatten())\n</code></pre>"},{"location":"api/#chimera.interfaces.perp.thermo_elastic_field.ThermoElasticField.get_indices","title":"<code>get_indices(tree, T_grid, P_grid)</code>  <code>staticmethod</code>","text":""},{"location":"api/#chimera.interfaces.perp.thermo_elastic_field.ThermoElasticField.get_indices--parameters","title":"Parameters","text":"<p>tree : TYPE     DESCRIPTION. T_grid : TYPE     DESCRIPTION. P_grid : TYPE     DESCRIPTION.</p>"},{"location":"api/#chimera.interfaces.perp.thermo_elastic_field.ThermoElasticField.get_indices--returns","title":"Returns","text":"<p>inds : TYPE     DESCRIPTION.</p> Source code in <code>src/chimera/interfaces/perp/thermo_elastic_field.py</code> <pre><code>@staticmethod\ndef get_indices(tree, T_grid, P_grid):\n    \"\"\"\n\n\n    Parameters\n    ----------\n    tree : TYPE\n        DESCRIPTION.\n    T_grid : TYPE\n        DESCRIPTION.\n    P_grid : TYPE\n        DESCRIPTION.\n\n    Returns\n    -------\n    inds : TYPE\n        DESCRIPTION.\n\n    \"\"\"\n    print(\"Retrieving moduli, density as function of P, T\")\n    # _,inds=tree.query(np.c_[T_grid,P_grid]) # changed with v0.1.6 # noqa: ERA001\n    # number of valid neighbors is returned too now. Must be ignored\n    _, inds, _ = tree.query(np.c_[T_grid, P_grid])\n    print(\"KDTree queried\")\n    return inds\n</code></pre>"},{"location":"api/#chimera.interfaces.perp.thermo_elastic_field.ThermoElasticField.get_tree","title":"<code>get_tree(tab)</code>  <code>staticmethod</code>","text":""},{"location":"api/#chimera.interfaces.perp.thermo_elastic_field.ThermoElasticField.get_tree--parameters","title":"Parameters","text":"<p>tab : TYPE     DESCRIPTION.</p>"},{"location":"api/#chimera.interfaces.perp.thermo_elastic_field.ThermoElasticField.get_tree--returns","title":"Returns","text":"<p>kdtree : TYPE     DESCRIPTION.</p> Source code in <code>src/chimera/interfaces/perp/thermo_elastic_field.py</code> <pre><code>@staticmethod\ndef get_tree(tab):\n    \"\"\"\n\n\n    Parameters\n    ----------\n    tab : TYPE\n        DESCRIPTION.\n\n    Returns\n    -------\n    kdtree : TYPE\n        DESCRIPTION.\n\n    \"\"\"\n    print(\"Creating a tree out of the P, T range of the thermodynamic\", \"dataset\")\n    T, P = tab.data[:2]\n    # since stagyy is in Pa, convert P [bar]-&gt;[Pa])\n    P *= 1e5\n    x, y = _TP_to_xy(T, P)\n    kdtree = KDTree(np.c_[x, y], leafsize=10)\n    print(\"KDTree Created\")\n    return kdtree\n</code></pre>"},{"location":"api/#chimera.interfaces.stag","title":"<code>stag</code>","text":""},{"location":"api/#chimera.interfaces.stag.loader","title":"<code>loader</code>","text":"<p>Simple wrappers to load coordinates and field data via stagpy. This assumes 2D yz spherical geometry.</p>"},{"location":"api/#chimera.interfaces.stag.loader.load_coords","title":"<code>load_coords(stagyydata)</code>","text":"<p>Simple stagpy wrapper to load coordinates from a StagyyData file.</p>"},{"location":"api/#chimera.interfaces.stag.loader.load_coords--parameters","title":"Parameters","text":"<p>stagyydata : stagpy.stagyydata.StagyyData     The model data output from stagyy, as read by stagpy.</p>"},{"location":"api/#chimera.interfaces.stag.loader.load_coords--returns","title":"Returns","text":"<p>r : numpy.ndarray     radial coordinates. theta : numpy.ndarray     azimuthal coordinates.</p> Source code in <code>src/chimera/interfaces/stag/loader.py</code> <pre><code>def load_coords(stagyydata):\n    \"\"\"\n    Simple stagpy wrapper to load coordinates from a StagyyData file.\n\n    Parameters\n    ----------\n    stagyydata : stagpy.stagyydata.StagyyData\n        The model data output from stagyy, as read by stagpy.\n\n    Returns\n    -------\n    r : numpy.ndarray\n        radial coordinates.\n    theta : numpy.ndarray\n        azimuthal coordinates.\n\n    \"\"\"\n    snap = stagyydata.snaps[0]\n    r = snap.geom.z_centers\n    theta = snap.geom.y_centers\n    return (r, theta)\n</code></pre>"},{"location":"api/#chimera.interfaces.stag.loader.load_field","title":"<code>load_field(stagyydata, name, i)</code>","text":"<p>Simple stagpy wrapper to load a field from a StagyyData file.</p>"},{"location":"api/#chimera.interfaces.stag.loader.load_field--parameters","title":"Parameters","text":"<p>stagyydata : stagpy.stagyydata.StagyyData     The model data output from stagyy, as read by stagpy. name : str     name of the field. i : int     snapshot index.</p>"},{"location":"api/#chimera.interfaces.stag.loader.load_field--returns","title":"Returns","text":"<p>TYPE numpy.ndarray     2D array representing the field.</p> Source code in <code>src/chimera/interfaces/stag/loader.py</code> <pre><code>def load_field(stagyydata, name, i):\n    \"\"\"\n    Simple stagpy wrapper to load a field from a StagyyData file.\n\n    Parameters\n    ----------\n    stagyydata : stagpy.stagyydata.StagyyData\n        The model data output from stagyy, as read by stagpy.\n    name : str\n        name of the field.\n    i : int\n        snapshot index.\n\n    Returns\n    -------\n    TYPE numpy.ndarray\n        2D array representing the field.\n\n    \"\"\"\n    snap = stagyydata.snaps[i]\n    snap_copy = Step(snap.istep, snap.sdat)\n\n    snap_copy.fields = CustomStagFields(\n        snap,\n        phyvars.FIELD,\n        phyvars.FIELD_EXTRA,\n        phyvars.FIELD_FILES,\n        phyvars.FIELD_FILES_H5,\n    )\n\n    return snap_copy.fields[name].values.squeeze()  # noqa: PD011\n</code></pre>"},{"location":"api/#chimera.thermo_data","title":"<code>thermo_data</code>","text":""},{"location":"api/#chimera.thermo_data.ThermoData","title":"<code>ThermoData</code>","text":"Source code in <code>src/chimera/thermo_data.py</code> <pre><code>class ThermoData:\n    def __init__(self):\n        \"\"\"\n        Initialize Thermochemical Data.\n\n        Returns\n        -------\n        None.\n\n        \"\"\"\n        self.perplex_path = \"\"  # path to tab files\n        self.thermo_var_names = []  # as read by stagyy\n        # c fields of stagyy + corresponding perplex tables, order must match!\n        self.c_field_names = [[], []]\n        self.elastic_path = \"/elastic-fields/\"\n        self.description = \"\"  # title to describe the set of tab files used\n        self.tabs = []\n        self.proj_names_dict = {}  # a dictionary associating\n        self.range = {}\n\n    @property\n    def c_field_names(self):\n        return self._c_field_names\n\n    @c_field_names.setter\n    def c_field_names(self, val):\n        self._c_field_names = val\n        cstagyy, cperplex = val\n        self.proj_names_dict = dict(zip(cstagyy, cperplex, strict=False))\n\n    def import_tab(self):\n        \"\"\"\n        When called, this method creates a Tab instance for each of the\n        fields, whose names and corresponding tab file title are stored in the\n        attribute c_field_names. These tabs are then stored in the attribute\n        tabs.\n        The overall P, T range is stored in the attributes Tminmax, Pminmax_Pa.\n\n        Returns\n        -------\n        None.\n\n        \"\"\"\n        self.tab_files = []\n        length = len(self.c_field_names[0])\n        Tminmax = np.zeros((length, 2))\n        Pminmax_Pa = np.zeros((length, 2))\n\n        for i, (_f, tb) in enumerate(zip(*self.c_field_names, strict=False)):\n            inpfl = self.perplex_path + tb + \".tab\"\n            tab = Tab(inpfl)\n            tab.load()\n            tab.remove_nans()\n            self.tabs.append(tab)\n            Tminmax[i] = tab.data[0].min(), tab.data[0].max()\n            Pminmax_Pa[i] = tab.data[1].min(), tab.data[1].max()\n\n        Pminmax_Pa *= 1e5\n        Tminmax = Tminmax[:, 0].min(), Tminmax[:, 1].max()\n        Pminmax_Pa = Pminmax_Pa[:, 0].min(), Pminmax_Pa[:, 1].max()\n        self.range[self.thermo_var_names[0]] = Tminmax\n        self.range[self.thermo_var_names[1]] = Pminmax_Pa\n\n    def save(self, save_path):\n        \"\"\"\n        Save a thermo_data somewhere.\n\n        Parameters\n        ----------\n        save_path : Str\n            Path where the class is saved.\n\n        Returns\n        -------\n        None.\n\n        \"\"\"\n        parent = save_path + \"/ThermoData/\"\n        try:\n            os.mkdir(parent)\n        except FileExistsError:\n            print(\n                \"Path \"\n                + parent\n                + \" exists. If file \"\n                + self.description\n                + \" already exists, it will be overwritten.\"\n            )\n\n        with open(parent + self.description + \".pkl\", \"wb\") as outp:\n            pickle.dump(self, outp, pickle.HIGHEST_PROTOCOL)\n\n    @staticmethod\n    def load(path):\n        with open(path + \".pkl\", \"rb\") as f:\n            return pickle.load(f)\n</code></pre>"},{"location":"api/#chimera.thermo_data.ThermoData.__init__","title":"<code>__init__()</code>","text":"<p>Initialize Thermochemical Data.</p>"},{"location":"api/#chimera.thermo_data.ThermoData.__init__--returns","title":"Returns","text":"<p>None.</p> Source code in <code>src/chimera/thermo_data.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initialize Thermochemical Data.\n\n    Returns\n    -------\n    None.\n\n    \"\"\"\n    self.perplex_path = \"\"  # path to tab files\n    self.thermo_var_names = []  # as read by stagyy\n    # c fields of stagyy + corresponding perplex tables, order must match!\n    self.c_field_names = [[], []]\n    self.elastic_path = \"/elastic-fields/\"\n    self.description = \"\"  # title to describe the set of tab files used\n    self.tabs = []\n    self.proj_names_dict = {}  # a dictionary associating\n    self.range = {}\n</code></pre>"},{"location":"api/#chimera.thermo_data.ThermoData.import_tab","title":"<code>import_tab()</code>","text":"<p>When called, this method creates a Tab instance for each of the fields, whose names and corresponding tab file title are stored in the attribute c_field_names. These tabs are then stored in the attribute tabs. The overall P, T range is stored in the attributes Tminmax, Pminmax_Pa.</p>"},{"location":"api/#chimera.thermo_data.ThermoData.import_tab--returns","title":"Returns","text":"<p>None.</p> Source code in <code>src/chimera/thermo_data.py</code> <pre><code>def import_tab(self):\n    \"\"\"\n    When called, this method creates a Tab instance for each of the\n    fields, whose names and corresponding tab file title are stored in the\n    attribute c_field_names. These tabs are then stored in the attribute\n    tabs.\n    The overall P, T range is stored in the attributes Tminmax, Pminmax_Pa.\n\n    Returns\n    -------\n    None.\n\n    \"\"\"\n    self.tab_files = []\n    length = len(self.c_field_names[0])\n    Tminmax = np.zeros((length, 2))\n    Pminmax_Pa = np.zeros((length, 2))\n\n    for i, (_f, tb) in enumerate(zip(*self.c_field_names, strict=False)):\n        inpfl = self.perplex_path + tb + \".tab\"\n        tab = Tab(inpfl)\n        tab.load()\n        tab.remove_nans()\n        self.tabs.append(tab)\n        Tminmax[i] = tab.data[0].min(), tab.data[0].max()\n        Pminmax_Pa[i] = tab.data[1].min(), tab.data[1].max()\n\n    Pminmax_Pa *= 1e5\n    Tminmax = Tminmax[:, 0].min(), Tminmax[:, 1].max()\n    Pminmax_Pa = Pminmax_Pa[:, 0].min(), Pminmax_Pa[:, 1].max()\n    self.range[self.thermo_var_names[0]] = Tminmax\n    self.range[self.thermo_var_names[1]] = Pminmax_Pa\n</code></pre>"},{"location":"api/#chimera.thermo_data.ThermoData.save","title":"<code>save(save_path)</code>","text":"<p>Save a thermo_data somewhere.</p>"},{"location":"api/#chimera.thermo_data.ThermoData.save--parameters","title":"Parameters","text":"<p>save_path : Str     Path where the class is saved.</p>"},{"location":"api/#chimera.thermo_data.ThermoData.save--returns","title":"Returns","text":"<p>None.</p> Source code in <code>src/chimera/thermo_data.py</code> <pre><code>def save(self, save_path):\n    \"\"\"\n    Save a thermo_data somewhere.\n\n    Parameters\n    ----------\n    save_path : Str\n        Path where the class is saved.\n\n    Returns\n    -------\n    None.\n\n    \"\"\"\n    parent = save_path + \"/ThermoData/\"\n    try:\n        os.mkdir(parent)\n    except FileExistsError:\n        print(\n            \"Path \"\n            + parent\n            + \" exists. If file \"\n            + self.description\n            + \" already exists, it will be overwritten.\"\n        )\n\n    with open(parent + self.description + \".pkl\", \"wb\") as outp:\n        pickle.dump(self, outp, pickle.HIGHEST_PROTOCOL)\n</code></pre>"},{"location":"api/#chimera.utils","title":"<code>utils</code>","text":"<p>Several misc utilities.</p>"},{"location":"api/#chimera.utils.to_cartesian","title":"<code>to_cartesian(r, theta)</code>","text":""},{"location":"api/#chimera.utils.to_cartesian--returns","title":"Returns","text":"<p>TYPE tuple of two numpy.array.     (x, y). The coordinates are unraveled.     len(x) = len(y) = len(r) * len(theta) = self.values.size</p> Source code in <code>src/chimera/utils.py</code> <pre><code>def to_cartesian(r, theta):\n    \"\"\"\n\n\n    Returns\n    -------\n    TYPE tuple of two numpy.array.\n        (x, y). The coordinates are unraveled.\n        len(x) = len(y) = len(r) * len(theta) = self.values.size\n\n    \"\"\"\n    r_grid, theta_grid = np.meshgrid(r, theta)\n    z = r_grid * np.exp(1j * theta_grid)\n    x, y = np.real(z).flatten(), np.imag(z).flatten()\n    return x, y\n</code></pre>"},{"location":"api/#chimera.velocity_model","title":"<code>velocity_model</code>","text":""},{"location":"api/#chimera.velocity_model.VelocityModel","title":"<code>VelocityModel</code>","text":"Source code in <code>src/chimera/velocity_model.py</code> <pre><code>class VelocityModel:\n    def __init__(self, model_name, i_t, t, x, y, Cnames=None, proj=None):\n        # model name, time info, radius of earth, other info\n        if Cnames is None:\n            Cnames = []\n        self.model_name = model_name\n        self.i_t = i_t\n        self.t = t\n        self.r_E_km = 6371.0  # TODO initialize this from proj/field/other info\n        self.proj = proj\n        # spatial coordinates\n        self.x = x\n        self.y = y\n        r, th = to_polar(self.x, self.y)\n        self.r, self.theta = r, th + np.pi / 2\n        # compositional fields and corresponding names\n        self.Cnames = Cnames\n        self.C = []\n        # T, P fields\n        self.T = []\n        self.P = []\n        # velocity fields\n        self.s = None\n        self.p = None\n        self.bulk = None\n        # density / velocity anomaly fields\n        self.rho_a = None\n        self.rho_stagyy_a = None\n        self.s_a = None\n        self.p_a = None\n        self.bulk_a = None\n        # average radial profiles\n        self.rho_prof = {\"r\": None, \"val\": []}\n        self.rho_stagyy_prof = {\"r\": None, \"val\": []}\n        self.s_prof = {\"r\": None, \"val\": []}\n        self.p_prof = {\"r\": None, \"val\": []}\n        self.bulk_prof = {\"r\": None, \"val\": []}\n        # average fields\n        self.K = None\n        self.G = None\n        self.rho = None\n        self.rho_stagyy = None\n        self.template = inparam_hetero  # inparam_hetero template\n\n    @property\n    def T(self):\n        return self._T\n\n    @T.setter\n    def T(self, value):\n        self._T = value\n        self.C = np.empty((len(self.Cnames), len(value)))\n\n    @property\n    def P(self):\n        return self._P\n\n    @P.setter\n    def P(self, value):\n        self._P = value\n\n    def compute_velocities(self, use_stagyy_rho):\n        rho = self.rho_stagyy if use_stagyy_rho else self.rho\n        self.stagyy_rho_used = use_stagyy_rho\n\n        K, G = self.K, self.G\n        self.s = compute_s(rho, G)\n        self.p = compute_p(rho, K, G)\n        self.bulk = compute_bulk(rho, K)\n\n    def load_moduli(self, path_moduli, proj_dict):\n        shape = self.C.shape\n        K_list = np.empty(shape)\n        G_list = np.empty(shape)\n        rho_list = np.empty(shape)\n\n        # TODO transfer the proj_dict from proj class to thermo_data class\n        for i, nm in enumerate(self.Cnames):\n            comp = proj_dict[nm]\n            G_path = path_moduli + comp + \"_\" + \"G\" + \".npy\"\n            K_path = path_moduli + comp + \"_\" + \"K\" + \".npy\"\n            rho_path = path_moduli + comp + \"_\" + \"rho\" + \".npy\"\n\n            K_list[i] = np.load(K_path)\n            G_list[i] = np.load(G_path)\n            rho_list[i] = np.load(rho_path)\n\n        return K_list, G_list, rho_list\n\n    def average(self, K_list, G_list, rho_list):\n        self.K = (reuss(K_list, self.C) + voigt(K_list, self.C)) / 2\n        self.G = (reuss(G_list, self.C) + voigt(G_list, self.C)) / 2\n        self.rho = voigt(rho_list, self.C)\n\n    def vel_rho_to_npy(self, destination):\n        model_name = self.model_name\n\n        print(\"Saving seismic velocity fields in \" + destination)\n        fname_s = model_name + \"_Vs.npy\"\n        fname_p = model_name + \"_Vp.npy\"\n        fname_b = model_name + \"_Vb.npy\"\n        fname_rho = model_name + \"_rho.npy\"\n\n        print(fname_s + \" for shear wave velocity\")\n        np.save(destination + fname_s, self.s)\n        print(fname_p + \" for body wave velocity\")\n        np.save(destination + fname_p, self.p)\n        print(fname_b + \" for bulk sound velocity\")\n        np.save(destination + fname_b, self.bulk)\n        print(fname_rho + \" for average density\")\n        np.save(destination + fname_rho, self.rho)\n\n    def get_rprofile(self, var=\"s\", round_param=3):\n        \"\"\"\n\n\n        Parameters\n        ----------\n        var : TYPE, optional\n            DESCRIPTION. The default is \"s\".\n        round_param : TYPE, optional\n            DESCRIPTION. The default is 3.\n\n        Returns\n        -------\n        rsel : TYPE\n            DESCRIPTION.\n        prof : TYPE\n            DESCRIPTION.\n\n        \"\"\"\n        # HACK to make it work with a previous version where the velocity\n        # model did not have the attribute quick_mode_on\n        quick_mode_on = _is_quick_mode_on(self)\n\n        # if you have a regular grid, this operation is easier\n        if quick_mode_on:\n            rsel, vel = self.r, getattrfrommod(self, var)\n            shape = [self.proj.geom[f\"n{c}tot\"] for c in (\"yz\")]\n            rsel, vel = (ar.reshape(shape) for ar in (rsel, vel))\n            rsel = rsel[0]\n            prof = np.mean(vel, axis=0)\n            return rsel, prof\n\n        shape = self.proj.custom_mesh_shape\n        if shape is None:\n            vel = getattrfrommod(self, var)\n            # hacky way to deal with a serious problem, numerical precision\n            rsel = np.sort(list(set(np.around(self.r, round_param))))\n\n            diffs = np.diff(rsel)\n            drmin = diffs[diffs &gt; 0].min() / 2\n\n            prof = np.empty(len(rsel))\n            for i, r_i in enumerate(rsel):\n                r1, r2 = r_i - drmin, r_i + drmin\n                level = (self.r &gt; r1) &amp; (self.r &lt; r2)\n                prof[i] = np.mean(vel[level])\n        else:\n            rsel, vel = self.r, getattrfrommod(self, var)\n            rsel, vel = (ar.reshape(shape) for ar in (rsel, vel))\n            rsel = rsel[0]\n            prof = np.mean(vel, axis=0)\n        return rsel, prof\n\n    def anomaly(self, var=\"s\", round_param=3, fac=100.0):\n        \"\"\"\n\n\n        Parameters\n        ----------\n        var : TYPE, optional\n            DESCRIPTION. The default is \"s\".\n        round_param : TYPE, optional\n            DESCRIPTION. The default is 3.\n        fac : TYPE, optional\n            DESCRIPTION. The default is 100.0.\n\n        Returns\n        -------\n        TYPE\n            DESCRIPTION.\n\n        \"\"\"\n        vel = getattr(self, var)\n        rprof, vprof = self.get_rprofile(var, round_param)\n        quick_mode_on = _is_quick_mode_on(self)\n\n        if quick_mode_on:\n            shape = [self.proj.geom[f\"n{c}tot\"] for c in (\"yz\")]\n            vel = vel.reshape(shape)\n            arr = fac * (vel - vprof) / vprof\n            setattr(self, var + \"_a\", arr.flatten())\n            setattr(self, var + \"_prof\", {\"r\": rprof, \"val\": vprof})\n        elif self.proj.custom_mesh_shape is None:\n            diffs = np.diff(rprof)\n            drmin = diffs[diffs &gt; 0].min() / 2\n\n            arr = fac * _anomaly(rprof, vprof, self.r, vel, drmin)\n\n            setattr(self, var + \"_a\", arr)\n            setattr(self, var + \"_prof\", {\"r\": rprof, \"val\": vprof})\n        else:\n            vel = vel.reshape(self.proj.custom_mesh_shape)\n            arr = fac * (vel - vprof) / vprof\n            setattr(self, var + \"_a\", arr.flatten())\n            setattr(self, var + \"_prof\", {\"r\": rprof, \"val\": vprof})\n\n        return getattr(self, var + \"_a\"), getattr(self, var + \"_prof\")\n\n    @staticmethod\n    def load(vmodel_path):\n        with open(vmodel_path + \"v_model_data.pkl\", \"rb\") as f:\n            return pickle.load(f)\n\n    def save(self, destination):\n        with open(destination + \"v_model_data.pkl\", \"wb\") as outp:\n            pickle.dump(self, outp, pickle.HIGHEST_PROTOCOL)\n\n    def export(\n        self,\n        destination,\n        fmt,\n        absolute=True,\n        fac=100,\n        fname=\"geodynamic_hetfile.sph\",\n        dtype=\"float32\",\n    ):\n        \"\"\"\n\n\n        Parameters\n        ----------\n        destination : TYPE\n            DESCRIPTION.\n        fmt : TYPE\n            DESCRIPTION.\n        absolute : TYPE, optional\n            DESCRIPTION. The default is True.\n        fac : TYPE, optional\n            DESCRIPTION. The default is 100.\n        fname : TYPE, optional\n            DESCRIPTION. Accepted file formats are .sph and .hdf5.\n            The default is \"geodynamic_hetfile.sph\".\n        dtype : TYPE, optional\n            DESCRIPTION. Used only if file is hdf5. The default is \"float\".\n\n        Returns\n        -------\n        None.\n\n        \"\"\"\n        r, th = self.r * self.r_E_km, self.theta * 180 / np.pi\n        th -= NINETY_DEG  # TODO check if it's always the same shift\n\n        val_type = \"\" if absolute else \"_a\"\n        adj = \"absolute values\" if absolute else \"relative perturbations\"\n        print(f\"Exporting model as {adj}\")\n        if not absolute:\n            _ = [self.anomaly(var, fac=fac) for var in [\"s\", \"p\", \"rho\"]]\n\n        print(f\"min/max thetas: {th.min():.1f}, {th.max():.1f} \")\n\n        if self.stagyy_rho_used:\n            rho = getattr(self, \"rho_stagyy\" + val_type)\n        else:\n            rho = getattr(self, \"rho\" + val_type)\n\n        s, p = getattr(self, \"s\" + val_type), getattr(self, \"p\" + val_type)\n\n        data = np.c_[r, th, p, s, rho]\n        # save the sph text file\n        fpath = destination + \"/\" + fname\n        name, extension = fname.rsplit(\".\")\n        if extension == \"sph\":\n            np.savetxt(fpath, data, header=str(len(data)), comments=\"\", fmt=fmt)\n        elif os.path.exists(fpath):\n            msg = \"hdf5 file with this name already exists.\"\n            raise OSError(msg)\n        else:\n            for d, d_name in zip(data.T, [\"r\", \"theta\", \"p\", \"s\", \"rho\"], strict=False):\n                with h5py.File(fpath, \"a\") as hf:\n                    hf.create_dataset(d_name, data=d, dtype=dtype)\n\n        # save a corresponding inparam_hetero, as needed by axisem\n        filled_template = self.template.format(fname)\n        with open(destination + \"/inparam_hetero\", \"w\") as inparam_file:\n            inparam_file.write(filled_template)\n\n    def get_hetero_profile(self):\n        pass\n\n    def plot_profiles(\n        self,\n        variables=None,\n        fig=None,\n        axs=None,\n        absolute=True,\n        external=None,\n        interp_kwargs=None,\n        third_variable=None,\n        plot_kwargs=None,\n        cmap_kwargs=None,\n    ):\n        \"\"\"\n\n\n        Parameters\n        ----------\n        variables : list, optional\n            DESCRIPTION. The default is [\"s\", \"p\", \"rho\"].\n        fig : TYPE, optional\n            DESCRIPTION. The default is None.\n        axs : TYPE, optional\n            DESCRIPTION. The default is None.\n        absolute : TYPE, optional\n            If True, the profiles are plotted as they are. Else, they are\n            compared to the ones from the supplied external 1D model.\n            The default is True.\n        external : tuple or list, optional\n            depth and (Vs, Vp, rho) profiles from 1D model. The value is\n            automatically set  to None if the parameter \"absolute\" = True.\n            The default is None.\n        interp_kwargs : dict, optional\n            DESCRIPTION. The default is {}.\n        third_variable : str or float or int, optional\n            If not None, use this variable to color the line. Accepted values:\n                - \"T\", str to plot as function of Temperature;\n                - float, to plot as function of mean T at that depth;\n                - integers, indicating the composition.\n            The default is None.\n\n        Raises\n        ------\n        ValueError\n            Will raise an error if absolute=+False and the external\n            model supplied does not conform to [z, (, ,)] or (z, (, ,))\n\n        Returns\n        -------\n        fig : TYPE\n            DESCRIPTION.\n        axs : TYPE\n            DESCRIPTION.\n\n        \"\"\"\n        if cmap_kwargs is None:\n            cmap_kwargs = {\"cmap\": \"hot\", \"vmin\": 300, \"vmax\": 4000}\n        if plot_kwargs is None:\n            plot_kwargs = {\"color\": \"r\"}\n        if interp_kwargs is None:\n            interp_kwargs = {\n                \"kind\": \"linear\",\n                \"bounds_error\": False,\n                \"fill_value\": \"extrapolate\",\n            }\n        if variables is None:\n            variables = [\"s\", \"p\", \"rho\"]\n        if absolute:\n            external = None\n\n        nv = len(variables)\n        r_prof_km = self.get_rprofile(\"s\")[0] * self.r_E_km\n        zprof_km = self.r_E_km - r_prof_km\n\n        labels = _create_labels(variables, absolute)\n        _profs = [self.get_rprofile(v)[-1] for v in variables]\n        if external is None:\n            profs = _profs\n        elif isinstance(external, tuple | list):\n            ext_z, ext_profs = external\n            _, profs = get_prof_pert(ext_z, ext_profs, zprof_km, _profs, interp_kwargs)\n        else:\n            profs = None\n            msg = (\n                \"External must be of type list or tuple, \"\n                \"the first element being the z coordinate \"\n                \"in km and the second a tuple with s, p, rho\"\n            )\n            raise ValueError(msg)\n        if axs is fig is None:\n            fig, axs = plt.subplots(1, nv, sharey=True, squeeze=False)\n            if axs.shape == (1, 1):\n                axs = [axs[1, 1]]\n\n        handle_mod = [None]\n\n        for ax, prof in zip(axs, profs, strict=False):\n            if third_variable is None:\n                handle_mod = ax.plot(prof, zprof_km, **plot_kwargs)\n            else:\n                cmap = cmap_kwargs[\"cmap\"]\n                vmin = cmap_kwargs[\"vmin\"]\n                vmax = cmap_kwargs[\"vmax\"]\n                if isinstance(third_variable, str):\n                    vals = self.get_rprofile(third_variable)[-1]\n                    # copied from matplotlib gallery (multicolored_line)\n                    points = np.array([prof, zprof_km]).T.reshape(-1, 1, 2)\n                    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n\n                    norm = plt.Normalize(vmin, vmax)\n                    lc = LineCollection(segments, cmap=cmap, norm=norm)\n                    # Set the values used for colormapping\n                    lc.set_array(vals)\n                    lc.set_linewidth(1)\n                    ax.add_collection(lc)\n                elif isinstance(third_variable, float):\n                    vals = self.get_rprofile(\"T\")[-1]\n                    val = np.interp(third_variable, zprof_km[::-1], vals[::-1])\n                    val -= vmin\n                    val /= vmax - vmin\n                    color = cm.get_cmap(cmap)(val)\n                    plot_kwargs[\"color\"] = color\n                    handle_mod = ax.plot(prof, zprof_km, **plot_kwargs)\n\n        [ax.set_ylim((zprof_km.max(), zprof_km.min())) for ax in axs]\n        [ax.set_xlabel(label) for ax, label in zip(axs, labels, strict=False)]\n        axs[0].set_ylabel(\"Depth [km]\")\n        axs[-1].legend(handle_mod, [\"Model\"])\n        plt.subplots_adjust(wspace=0)\n        plt.title(self.model_name)\n\n        return fig, axs\n\n    @staticmethod\n    def import_hetfile(vel_model_path, variabs=None, fname=\"geodynamic_hetfile.sph\"):\n        if variabs is None:\n            variabs = [\"r\", \"theta\", \"p\", \"s\", \"rho\"]\n        name, extension = fname.rsplit(\".\")\n        fpath = vel_model_path + \"/\" + fname\n\n        if extension == \"sph\":\n            print(\"loadtxt\")\n            dic = {\"r\": 0, \"theta\": 1, \"p\": 2, \"s\": 3, \"rho\": 4}\n            usecols = [dic[v] for v in variabs]\n            data = np.loadtxt(fpath, skiprows=1, usecols=usecols).T\n        elif extension == \"hdf5\":\n            data = []\n            for d_name in variabs:\n                with h5py.File(fpath, \"r\") as file:\n                    d = np.array(file.get(d_name))\n                    data.append(d)\n            if isinstance(data, list) and len(data) &lt; 2:  # noqa: PLR2004\n                data = data[0]\n        else:\n            data = None\n        return data\n\n    @staticmethod\n    def plot_ext_prof(profs, axs, r_core_m=3481e3, r_Earth_m=6371e3, c=\"b\", lbl=None):\n        \"\"\"\n\n\n        Parameters\n        ----------\n        profs : str or list like\n            Either the path to the 1D profiles or a tuple built like this:\n                (depth_in_km, [s, p, rho]).\n        axs : TYPE\n            DESCRIPTION.\n        r_core_m : float, optional\n            DESCRIPTION. The default is 3481e3.\n        r_Earth_m : float, optional\n            DESCRIPTION. The default is 6371e3.\n        c : str, optional\n            Color. The default is \"b\".\n        lbl : str, optional\n            label. The default is None.\n\n        Returns\n        -------\n        None.\n\n        \"\"\"\n        if isinstance(profs, str):\n            zprem_km, _profs = get_ext_prof(profs, r_core_m, r_Earth_m)\n        elif isinstance(profs, list | tuple):\n            zprem_km, _profs = profs\n\n        for ax, prof in zip(axs, _profs, strict=False):\n            ax.plot(prof, zprem_km, c=c, label=lbl)\n        axs[0].legend()\n\n    def fourier(self, var=\"s_a\", demean=False, psd=True, **fft_kwargs):\n        if not _is_quick_mode_on(self):\n            msg = \"Function has only been implemented on the regular grid\"\n            raise NotImplementedError(msg)\n\n        shape = [self.proj.geom[f\"n{c}tot\"] for c in (\"yz\")]\n\n        theta = self.theta\n        lat = np.reshape(theta, shape)[:, 0] * 180 / np.pi\n        r = np.reshape(self.r, shape)[0]\n        data = np.reshape(getattrfrommod(self, var), shape).T\n\n        _data = data - np.mean(data, axis=1)[:, np.newaxis] if demean else data\n\n        spectrum_r = np.fft.rfft(_data, axis=1, **fft_kwargs)\n        fax = np.fft.rfftfreq(len(lat), lat[1] - lat[0])\n\n        if psd:\n            spectrum_r = (np.abs(spectrum_r) / len(lat)) ** 2\n        return r * self.r_E_km, lat, fax, spectrum_r\n\n    def sh(\n        self,\n        var=\"s_a\",\n        method=\"extend\",\n        shift_deg=0,\n        sh_type=\"GL\",\n        norm=\"4pi\",\n        cs_phase=1,\n        lmax=None,\n        demean=False,\n    ):\n        _norm = {\"4pi\": 1, \"schmidt\": 2, \"unnorm\": 3, \"ortho\": 4}\n        n_i_d = _norm[norm]\n        lmax_calc = lmax\n\n        if not _is_quick_mode_on(self):\n            msg = \"The function has only been implemented on a regular grid\"\n            raise NotImplementedError(msg)\n\n        raw = getattrfrommod(self, var)\n\n        shape = [self.proj.geom[f\"n{c}tot\"] for c in (\"yz\")]\n\n        theta = self.theta\n        r = np.reshape(self.r, shape)[0]\n        if method == \"circle\":\n            msg = \"Method of Arnould et al. 2018 not yet implemented\"\n            raise NotImplementedError(msg)\n        if method == \"extend\":\n            data = np.reshape(raw, shape).T\n            lat = np.reshape(theta, shape)[:, 0] * 180 / np.pi\n            if sh_type == \"DH\":\n                hemisphere = (lat &gt; -NINETY_DEG) &amp; (lat &lt;= NINETY_DEG)\n            else:\n                hemisphere = (lat &gt; -NINETY_DEG) &amp; (lat &lt; NINETY_DEG)\n            shift = int(np.rint(shift_deg / (np.abs(lat[1] - lat[0]))))\n            data = data[:, np.roll(hemisphere, shift)]\n            lat = lat[hemisphere]\n            clm_z = np.zeros(len(r), dtype=pysh.SHCoeffs)\n\n            if lmax_calc is None:\n                lmax_calc = len(lat) - 1\n            ext_shape = (len(r), len(lat), 2 * (len(lat) - 1) + 1)\n            data_ext = np.broadcast_to(data[:, :, np.newaxis], ext_shape)\n\n            if sh_type == \"GL\":\n                newlat, newlon = pysh.expand.GLQGridCoord(lmax_calc)\n                ext_shape = (len(r), len(lat), 2 * (len(lat) - 1) + 1)\n                data_ext = np.broadcast_to(data[:, :, np.newaxis], ext_shape)\n                for i, d in enumerate(data_ext):\n                    mu = np.mean(d) if demean else 0\n                    cilm = pysh.expand.SHExpandGLQ(\n                        d - mu, \"\", \"\", cs_phase, n_i_d, lmax_calc\n                    )\n                    clm_z[i] = pysh.SHCoeffs.from_array(\n                        cilm, csphase=cs_phase, normalization=norm\n                    )\n            elif sh_type == \"DH\":\n                lon = np.linspace(0, 359, 2 * len(lat))\n                newlat, newlon = lat, lon\n                ext_shape = (len(r), len(lat), len(lat))\n                data_ext = np.broadcast_to(data[:, :, np.newaxis], ext_shape)\n                for i, d in enumerate(data_ext):\n                    mu = np.mean(d) if demean else 0\n                    cilm = pysh.expand.SHExpandDH(d - mu, n_i_d, 1, cs_phase, lmax_calc)\n                    clm_z[i] = pysh.SHCoeffs.from_array(\n                        cilm, csphase=cs_phase, normalization=norm\n                    )\n            else:\n                lon = np.linspace(0, 359, 2 * len(lat))\n                xx, yy = np.meshgrid(lon, lat)\n                newlon, newlat = xx.flatten(), yy.flatten()\n                for i, d in enumerate(data_ext):\n                    mu = np.mean(d) if demean else 0\n                    cilm = pysh.expand.SHExpandLSQ(\n                        (d - mu).flatten(), newlon, newlat, lmax_calc, n_i_d, cs_phase\n                    )\n                    clm_z[i] = pysh.SHCoeffs.from_array(\n                        cilm, csphase=cs_phase, normalization=norm\n                    )\n\n            return (lmax_calc, clm_z, r * self.r_E_km, newlat, newlon)\n        return None\n</code></pre>"},{"location":"api/#chimera.velocity_model.VelocityModel.anomaly","title":"<code>anomaly(var='s', round_param=3, fac=100.0)</code>","text":""},{"location":"api/#chimera.velocity_model.VelocityModel.anomaly--parameters","title":"Parameters","text":"<p>var : TYPE, optional     DESCRIPTION. The default is \"s\". round_param : TYPE, optional     DESCRIPTION. The default is 3. fac : TYPE, optional     DESCRIPTION. The default is 100.0.</p>"},{"location":"api/#chimera.velocity_model.VelocityModel.anomaly--returns","title":"Returns","text":"<p>TYPE     DESCRIPTION.</p> Source code in <code>src/chimera/velocity_model.py</code> <pre><code>def anomaly(self, var=\"s\", round_param=3, fac=100.0):\n    \"\"\"\n\n\n    Parameters\n    ----------\n    var : TYPE, optional\n        DESCRIPTION. The default is \"s\".\n    round_param : TYPE, optional\n        DESCRIPTION. The default is 3.\n    fac : TYPE, optional\n        DESCRIPTION. The default is 100.0.\n\n    Returns\n    -------\n    TYPE\n        DESCRIPTION.\n\n    \"\"\"\n    vel = getattr(self, var)\n    rprof, vprof = self.get_rprofile(var, round_param)\n    quick_mode_on = _is_quick_mode_on(self)\n\n    if quick_mode_on:\n        shape = [self.proj.geom[f\"n{c}tot\"] for c in (\"yz\")]\n        vel = vel.reshape(shape)\n        arr = fac * (vel - vprof) / vprof\n        setattr(self, var + \"_a\", arr.flatten())\n        setattr(self, var + \"_prof\", {\"r\": rprof, \"val\": vprof})\n    elif self.proj.custom_mesh_shape is None:\n        diffs = np.diff(rprof)\n        drmin = diffs[diffs &gt; 0].min() / 2\n\n        arr = fac * _anomaly(rprof, vprof, self.r, vel, drmin)\n\n        setattr(self, var + \"_a\", arr)\n        setattr(self, var + \"_prof\", {\"r\": rprof, \"val\": vprof})\n    else:\n        vel = vel.reshape(self.proj.custom_mesh_shape)\n        arr = fac * (vel - vprof) / vprof\n        setattr(self, var + \"_a\", arr.flatten())\n        setattr(self, var + \"_prof\", {\"r\": rprof, \"val\": vprof})\n\n    return getattr(self, var + \"_a\"), getattr(self, var + \"_prof\")\n</code></pre>"},{"location":"api/#chimera.velocity_model.VelocityModel.export","title":"<code>export(destination, fmt, absolute=True, fac=100, fname='geodynamic_hetfile.sph', dtype='float32')</code>","text":""},{"location":"api/#chimera.velocity_model.VelocityModel.export--parameters","title":"Parameters","text":"<p>destination : TYPE     DESCRIPTION. fmt : TYPE     DESCRIPTION. absolute : TYPE, optional     DESCRIPTION. The default is True. fac : TYPE, optional     DESCRIPTION. The default is 100. fname : TYPE, optional     DESCRIPTION. Accepted file formats are .sph and .hdf5.     The default is \"geodynamic_hetfile.sph\". dtype : TYPE, optional     DESCRIPTION. Used only if file is hdf5. The default is \"float\".</p>"},{"location":"api/#chimera.velocity_model.VelocityModel.export--returns","title":"Returns","text":"<p>None.</p> Source code in <code>src/chimera/velocity_model.py</code> <pre><code>def export(\n    self,\n    destination,\n    fmt,\n    absolute=True,\n    fac=100,\n    fname=\"geodynamic_hetfile.sph\",\n    dtype=\"float32\",\n):\n    \"\"\"\n\n\n    Parameters\n    ----------\n    destination : TYPE\n        DESCRIPTION.\n    fmt : TYPE\n        DESCRIPTION.\n    absolute : TYPE, optional\n        DESCRIPTION. The default is True.\n    fac : TYPE, optional\n        DESCRIPTION. The default is 100.\n    fname : TYPE, optional\n        DESCRIPTION. Accepted file formats are .sph and .hdf5.\n        The default is \"geodynamic_hetfile.sph\".\n    dtype : TYPE, optional\n        DESCRIPTION. Used only if file is hdf5. The default is \"float\".\n\n    Returns\n    -------\n    None.\n\n    \"\"\"\n    r, th = self.r * self.r_E_km, self.theta * 180 / np.pi\n    th -= NINETY_DEG  # TODO check if it's always the same shift\n\n    val_type = \"\" if absolute else \"_a\"\n    adj = \"absolute values\" if absolute else \"relative perturbations\"\n    print(f\"Exporting model as {adj}\")\n    if not absolute:\n        _ = [self.anomaly(var, fac=fac) for var in [\"s\", \"p\", \"rho\"]]\n\n    print(f\"min/max thetas: {th.min():.1f}, {th.max():.1f} \")\n\n    if self.stagyy_rho_used:\n        rho = getattr(self, \"rho_stagyy\" + val_type)\n    else:\n        rho = getattr(self, \"rho\" + val_type)\n\n    s, p = getattr(self, \"s\" + val_type), getattr(self, \"p\" + val_type)\n\n    data = np.c_[r, th, p, s, rho]\n    # save the sph text file\n    fpath = destination + \"/\" + fname\n    name, extension = fname.rsplit(\".\")\n    if extension == \"sph\":\n        np.savetxt(fpath, data, header=str(len(data)), comments=\"\", fmt=fmt)\n    elif os.path.exists(fpath):\n        msg = \"hdf5 file with this name already exists.\"\n        raise OSError(msg)\n    else:\n        for d, d_name in zip(data.T, [\"r\", \"theta\", \"p\", \"s\", \"rho\"], strict=False):\n            with h5py.File(fpath, \"a\") as hf:\n                hf.create_dataset(d_name, data=d, dtype=dtype)\n\n    # save a corresponding inparam_hetero, as needed by axisem\n    filled_template = self.template.format(fname)\n    with open(destination + \"/inparam_hetero\", \"w\") as inparam_file:\n        inparam_file.write(filled_template)\n</code></pre>"},{"location":"api/#chimera.velocity_model.VelocityModel.get_rprofile","title":"<code>get_rprofile(var='s', round_param=3)</code>","text":""},{"location":"api/#chimera.velocity_model.VelocityModel.get_rprofile--parameters","title":"Parameters","text":"<p>var : TYPE, optional     DESCRIPTION. The default is \"s\". round_param : TYPE, optional     DESCRIPTION. The default is 3.</p>"},{"location":"api/#chimera.velocity_model.VelocityModel.get_rprofile--returns","title":"Returns","text":"<p>rsel : TYPE     DESCRIPTION. prof : TYPE     DESCRIPTION.</p> Source code in <code>src/chimera/velocity_model.py</code> <pre><code>def get_rprofile(self, var=\"s\", round_param=3):\n    \"\"\"\n\n\n    Parameters\n    ----------\n    var : TYPE, optional\n        DESCRIPTION. The default is \"s\".\n    round_param : TYPE, optional\n        DESCRIPTION. The default is 3.\n\n    Returns\n    -------\n    rsel : TYPE\n        DESCRIPTION.\n    prof : TYPE\n        DESCRIPTION.\n\n    \"\"\"\n    # HACK to make it work with a previous version where the velocity\n    # model did not have the attribute quick_mode_on\n    quick_mode_on = _is_quick_mode_on(self)\n\n    # if you have a regular grid, this operation is easier\n    if quick_mode_on:\n        rsel, vel = self.r, getattrfrommod(self, var)\n        shape = [self.proj.geom[f\"n{c}tot\"] for c in (\"yz\")]\n        rsel, vel = (ar.reshape(shape) for ar in (rsel, vel))\n        rsel = rsel[0]\n        prof = np.mean(vel, axis=0)\n        return rsel, prof\n\n    shape = self.proj.custom_mesh_shape\n    if shape is None:\n        vel = getattrfrommod(self, var)\n        # hacky way to deal with a serious problem, numerical precision\n        rsel = np.sort(list(set(np.around(self.r, round_param))))\n\n        diffs = np.diff(rsel)\n        drmin = diffs[diffs &gt; 0].min() / 2\n\n        prof = np.empty(len(rsel))\n        for i, r_i in enumerate(rsel):\n            r1, r2 = r_i - drmin, r_i + drmin\n            level = (self.r &gt; r1) &amp; (self.r &lt; r2)\n            prof[i] = np.mean(vel[level])\n    else:\n        rsel, vel = self.r, getattrfrommod(self, var)\n        rsel, vel = (ar.reshape(shape) for ar in (rsel, vel))\n        rsel = rsel[0]\n        prof = np.mean(vel, axis=0)\n    return rsel, prof\n</code></pre>"},{"location":"api/#chimera.velocity_model.VelocityModel.plot_ext_prof","title":"<code>plot_ext_prof(profs, axs, r_core_m=3481000.0, r_Earth_m=6371000.0, c='b', lbl=None)</code>  <code>staticmethod</code>","text":""},{"location":"api/#chimera.velocity_model.VelocityModel.plot_ext_prof--parameters","title":"Parameters","text":"<p>profs : str or list like     Either the path to the 1D profiles or a tuple built like this:         (depth_in_km, [s, p, rho]). axs : TYPE     DESCRIPTION. r_core_m : float, optional     DESCRIPTION. The default is 3481e3. r_Earth_m : float, optional     DESCRIPTION. The default is 6371e3. c : str, optional     Color. The default is \"b\". lbl : str, optional     label. The default is None.</p>"},{"location":"api/#chimera.velocity_model.VelocityModel.plot_ext_prof--returns","title":"Returns","text":"<p>None.</p> Source code in <code>src/chimera/velocity_model.py</code> <pre><code>@staticmethod\ndef plot_ext_prof(profs, axs, r_core_m=3481e3, r_Earth_m=6371e3, c=\"b\", lbl=None):\n    \"\"\"\n\n\n    Parameters\n    ----------\n    profs : str or list like\n        Either the path to the 1D profiles or a tuple built like this:\n            (depth_in_km, [s, p, rho]).\n    axs : TYPE\n        DESCRIPTION.\n    r_core_m : float, optional\n        DESCRIPTION. The default is 3481e3.\n    r_Earth_m : float, optional\n        DESCRIPTION. The default is 6371e3.\n    c : str, optional\n        Color. The default is \"b\".\n    lbl : str, optional\n        label. The default is None.\n\n    Returns\n    -------\n    None.\n\n    \"\"\"\n    if isinstance(profs, str):\n        zprem_km, _profs = get_ext_prof(profs, r_core_m, r_Earth_m)\n    elif isinstance(profs, list | tuple):\n        zprem_km, _profs = profs\n\n    for ax, prof in zip(axs, _profs, strict=False):\n        ax.plot(prof, zprem_km, c=c, label=lbl)\n    axs[0].legend()\n</code></pre>"},{"location":"api/#chimera.velocity_model.VelocityModel.plot_profiles","title":"<code>plot_profiles(variables=None, fig=None, axs=None, absolute=True, external=None, interp_kwargs=None, third_variable=None, plot_kwargs=None, cmap_kwargs=None)</code>","text":""},{"location":"api/#chimera.velocity_model.VelocityModel.plot_profiles--parameters","title":"Parameters","text":"<p>variables : list, optional     DESCRIPTION. The default is [\"s\", \"p\", \"rho\"]. fig : TYPE, optional     DESCRIPTION. The default is None. axs : TYPE, optional     DESCRIPTION. The default is None. absolute : TYPE, optional     If True, the profiles are plotted as they are. Else, they are     compared to the ones from the supplied external 1D model.     The default is True. external : tuple or list, optional     depth and (Vs, Vp, rho) profiles from 1D model. The value is     automatically set  to None if the parameter \"absolute\" = True.     The default is None. interp_kwargs : dict, optional     DESCRIPTION. The default is {}. third_variable : str or float or int, optional     If not None, use this variable to color the line. Accepted values:         - \"T\", str to plot as function of Temperature;         - float, to plot as function of mean T at that depth;         - integers, indicating the composition.     The default is None.</p>"},{"location":"api/#chimera.velocity_model.VelocityModel.plot_profiles--raises","title":"Raises","text":"<p>ValueError     Will raise an error if absolute=+False and the external     model supplied does not conform to [z, (, ,)] or (z, (, ,))</p>"},{"location":"api/#chimera.velocity_model.VelocityModel.plot_profiles--returns","title":"Returns","text":"<p>fig : TYPE     DESCRIPTION. axs : TYPE     DESCRIPTION.</p> Source code in <code>src/chimera/velocity_model.py</code> <pre><code>def plot_profiles(\n    self,\n    variables=None,\n    fig=None,\n    axs=None,\n    absolute=True,\n    external=None,\n    interp_kwargs=None,\n    third_variable=None,\n    plot_kwargs=None,\n    cmap_kwargs=None,\n):\n    \"\"\"\n\n\n    Parameters\n    ----------\n    variables : list, optional\n        DESCRIPTION. The default is [\"s\", \"p\", \"rho\"].\n    fig : TYPE, optional\n        DESCRIPTION. The default is None.\n    axs : TYPE, optional\n        DESCRIPTION. The default is None.\n    absolute : TYPE, optional\n        If True, the profiles are plotted as they are. Else, they are\n        compared to the ones from the supplied external 1D model.\n        The default is True.\n    external : tuple or list, optional\n        depth and (Vs, Vp, rho) profiles from 1D model. The value is\n        automatically set  to None if the parameter \"absolute\" = True.\n        The default is None.\n    interp_kwargs : dict, optional\n        DESCRIPTION. The default is {}.\n    third_variable : str or float or int, optional\n        If not None, use this variable to color the line. Accepted values:\n            - \"T\", str to plot as function of Temperature;\n            - float, to plot as function of mean T at that depth;\n            - integers, indicating the composition.\n        The default is None.\n\n    Raises\n    ------\n    ValueError\n        Will raise an error if absolute=+False and the external\n        model supplied does not conform to [z, (, ,)] or (z, (, ,))\n\n    Returns\n    -------\n    fig : TYPE\n        DESCRIPTION.\n    axs : TYPE\n        DESCRIPTION.\n\n    \"\"\"\n    if cmap_kwargs is None:\n        cmap_kwargs = {\"cmap\": \"hot\", \"vmin\": 300, \"vmax\": 4000}\n    if plot_kwargs is None:\n        plot_kwargs = {\"color\": \"r\"}\n    if interp_kwargs is None:\n        interp_kwargs = {\n            \"kind\": \"linear\",\n            \"bounds_error\": False,\n            \"fill_value\": \"extrapolate\",\n        }\n    if variables is None:\n        variables = [\"s\", \"p\", \"rho\"]\n    if absolute:\n        external = None\n\n    nv = len(variables)\n    r_prof_km = self.get_rprofile(\"s\")[0] * self.r_E_km\n    zprof_km = self.r_E_km - r_prof_km\n\n    labels = _create_labels(variables, absolute)\n    _profs = [self.get_rprofile(v)[-1] for v in variables]\n    if external is None:\n        profs = _profs\n    elif isinstance(external, tuple | list):\n        ext_z, ext_profs = external\n        _, profs = get_prof_pert(ext_z, ext_profs, zprof_km, _profs, interp_kwargs)\n    else:\n        profs = None\n        msg = (\n            \"External must be of type list or tuple, \"\n            \"the first element being the z coordinate \"\n            \"in km and the second a tuple with s, p, rho\"\n        )\n        raise ValueError(msg)\n    if axs is fig is None:\n        fig, axs = plt.subplots(1, nv, sharey=True, squeeze=False)\n        if axs.shape == (1, 1):\n            axs = [axs[1, 1]]\n\n    handle_mod = [None]\n\n    for ax, prof in zip(axs, profs, strict=False):\n        if third_variable is None:\n            handle_mod = ax.plot(prof, zprof_km, **plot_kwargs)\n        else:\n            cmap = cmap_kwargs[\"cmap\"]\n            vmin = cmap_kwargs[\"vmin\"]\n            vmax = cmap_kwargs[\"vmax\"]\n            if isinstance(third_variable, str):\n                vals = self.get_rprofile(third_variable)[-1]\n                # copied from matplotlib gallery (multicolored_line)\n                points = np.array([prof, zprof_km]).T.reshape(-1, 1, 2)\n                segments = np.concatenate([points[:-1], points[1:]], axis=1)\n\n                norm = plt.Normalize(vmin, vmax)\n                lc = LineCollection(segments, cmap=cmap, norm=norm)\n                # Set the values used for colormapping\n                lc.set_array(vals)\n                lc.set_linewidth(1)\n                ax.add_collection(lc)\n            elif isinstance(third_variable, float):\n                vals = self.get_rprofile(\"T\")[-1]\n                val = np.interp(third_variable, zprof_km[::-1], vals[::-1])\n                val -= vmin\n                val /= vmax - vmin\n                color = cm.get_cmap(cmap)(val)\n                plot_kwargs[\"color\"] = color\n                handle_mod = ax.plot(prof, zprof_km, **plot_kwargs)\n\n    [ax.set_ylim((zprof_km.max(), zprof_km.min())) for ax in axs]\n    [ax.set_xlabel(label) for ax, label in zip(axs, labels, strict=False)]\n    axs[0].set_ylabel(\"Depth [km]\")\n    axs[-1].legend(handle_mod, [\"Model\"])\n    plt.subplots_adjust(wspace=0)\n    plt.title(self.model_name)\n\n    return fig, axs\n</code></pre>"},{"location":"api/#chimera.velocity_model.get_ext_prof","title":"<code>get_ext_prof(path, r_core_m=3481000.0, r_Earth_m=6371000.0, usecols=(0, 3))</code>","text":"<p>Return vs, vp, density out of an external 1D model (an axisem .bm file) and their depth coordinates in kms.</p>"},{"location":"api/#chimera.velocity_model.get_ext_prof--parameters","title":"Parameters","text":"<p>path : str     Path of an external 1D model, an axisem .bm file     (caution: it is assumed that the first 6 lines are the header.      It is also assumed that the model is isotropic, r units are in      meters and columns are r, rho, vpv, vsv, qka, qmu). r_core_m : float, optional     DESCRIPTION. The default is 3481e3. r_Earth_m : float, optional     DESCRIPTION. The default is 6371e3. usecols : tuple, optional     Use the columns from usecols[0] to usecols[-1]. The default is (0,3).</p>"},{"location":"api/#chimera.velocity_model.get_ext_prof--returns","title":"Returns","text":"<p>zprem_km  : numpy.ndarray     Array containing the depth coordinates in kms. profs : list     Values obtained from the 1D model supplied.     By default, vs, vp, density are returned.     The parameter usecols may be used to trim/extend this list.     The extended list is vs, vp, density, qka, qmu</p> Source code in <code>src/chimera/velocity_model.py</code> <pre><code>def get_ext_prof(path, r_core_m=3481e3, r_Earth_m=6371e3, usecols=(0, 3)):\n    \"\"\"\n    Return vs, vp, density out of an external 1D model (an axisem .bm file) and\n    their depth coordinates in kms.\n\n    Parameters\n    ----------\n    path : str\n        Path of an external 1D model, an axisem .bm file\n        (caution: it is assumed that the first 6 lines are the header.\n         It is also assumed that the model is isotropic, r units are in\n         meters and columns are r, rho, vpv, vsv, qka, qmu).\n    r_core_m : float, optional\n        DESCRIPTION. The default is 3481e3.\n    r_Earth_m : float, optional\n        DESCRIPTION. The default is 6371e3.\n    usecols : tuple, optional\n        Use the columns from usecols[0] to usecols[-1]. The default is (0,3).\n\n\n    Returns\n    -------\n    zprem_km  : numpy.ndarray\n        Array containing the depth coordinates in kms.\n    profs : list\n        Values obtained from the 1D model supplied.\n        By default, vs, vp, density are returned.\n        The parameter usecols may be used to trim/extend this list.\n        The extended list is vs, vp, density, qka, qmu\n\n\n\n    \"\"\"\n    rprem, rhoprem, vpprem, vsprem, qka, qmu = np.loadtxt(path, skiprows=6, unpack=True)\n    mantle = rprem &gt;= r_core_m\n    rprem, rhoprem = rprem[mantle], rhoprem[mantle]\n    vpprem, vsprem = vpprem[mantle], vsprem[mantle]\n    qka, qmu = qka[mantle], qmu[mantle]\n\n    zprem_km = (r_Earth_m - rprem) / 1e3\n    profs = [vsprem, vpprem, rhoprem, qka, qmu]\n    return zprem_km, profs[usecols[0] : usecols[1]]\n</code></pre>"}]}